{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CatFocal_DenseNet121-30_CAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPbIi0c4QAYM/NZR/uyiT7x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filmerxyz/JSTP-22_SkinDiseaseClassificationUsingMachineLearning/blob/master/CatFocal_DenseNet121_30_CAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGAbDjt3rz_5",
        "colab_type": "text"
      },
      "source": [
        "# **Check GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KeAnM3PXlUe",
        "colab_type": "code",
        "outputId": "edcd8163-3fb2-42db-b09b-2683de2fa58a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May 31 19:00:11 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dGHmmXA-fCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "01825200-8a96-479f-e9cd-83a49af91590"
      },
      "source": [
        "!pip install -U efficientnet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: efficientnet in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbD3Qq816yZZ",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tch5If72HQeC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44cf7add-7e2c-4e29-82a5-d61e638803d0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import efficientnet.keras as enet\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from os.path import join\n",
        "\n",
        "from ham10000_utils_functions import plot_confusion_matrix, normalize, deprocess_image, my_decode_predictions, guided_backprop, grad_cam, compute_saliency"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPwDTos761Oq",
        "colab_type": "text"
      },
      "source": [
        "# **Clone Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHjfNRvqza-U",
        "colab_type": "code",
        "outputId": "20190ee0-d09d-426a-fcba-733b3a9e5924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/EvilPickle-PCSHSPT/ham10000-with-one-image-folder"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ham10000-with-one-image-folder' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__IXKxBZVymL",
        "colab_type": "text"
      },
      "source": [
        "# **Constant Variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ2LKSeHQRnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 7\n",
        "STEPS = 16\n",
        "\n",
        "LR = 3e-5 # Learning rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrpBmL7mVlJC",
        "colab_type": "text"
      },
      "source": [
        "# **Prepare Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnsBJBcPL3SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('/content/ham10000-with-one-image-folder/HAM10000_metadata.csv')\n",
        "data['image_full_name']=data['image_id']+'.jpg'\n",
        "X=data[['image_full_name','dx','lesion_id']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rt4v6YTM0Fr",
        "colab_type": "code",
        "outputId": "fa282c94-3693-4733-e180-c9cb70ef122e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>image_full_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0027419.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0025030.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0026769.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0025661.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>ISIC_0031633.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx  ...   sex  localization   image_full_name\n",
              "0  HAM_0000118  ISIC_0027419  bkl  ...  male         scalp  ISIC_0027419.jpg\n",
              "1  HAM_0000118  ISIC_0025030  bkl  ...  male         scalp  ISIC_0025030.jpg\n",
              "2  HAM_0002730  ISIC_0026769  bkl  ...  male         scalp  ISIC_0026769.jpg\n",
              "3  HAM_0002730  ISIC_0025661  bkl  ...  male         scalp  ISIC_0025661.jpg\n",
              "4  HAM_0001466  ISIC_0031633  bkl  ...  male           ear  ISIC_0031633.jpg\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_1JsUvHGMGi",
        "colab_type": "text"
      },
      "source": [
        "### **Split Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1q1WsAhM-HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Y=X.pop('dx').to_frame()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ghodz0zOJ0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.concat([X_train,y_train],axis=1)\n",
        "val = pd.concat([X_val,y_val],axis=1)\n",
        "test = pd.concat([X_test,y_test],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG6iaiiyMHmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train['dx'])\n",
        "name_as_indexes_train = encoder.transform(train['dx']) \n",
        "train['label'] = name_as_indexes_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLryd9huOStO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(val['dx'])\n",
        "name_as_indexes_val = encoder.transform(val['dx']) \n",
        "val['label'] = name_as_indexes_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VYdnvBOOUek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder=LabelEncoder()\n",
        "encoder.fit(test['dx'])\n",
        "name_as_indexes_test = encoder.transform(test['dx']) \n",
        "test['label'] = name_as_indexes_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDOtGZx7YiJa",
        "colab_type": "text"
      },
      "source": [
        "### **Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6snNZRZOWaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = ImageDataGenerator(rescale = 1./255,\n",
        "                                     rotation_range=360,  \n",
        "                                     zoom_range = 0.3,\n",
        "                                     horizontal_flip=True,\n",
        "                                     vertical_flip=True,\n",
        "                                     fill_mode='reflect')\n",
        "                                    \n",
        "val_generator=ImageDataGenerator(rescale = 1./255)\n",
        "test_generator=ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdF3KvYwOfC5",
        "colab_type": "code",
        "outputId": "13033298-dad3-4784-e7db-b300ed5a907e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_data= train_generator.flow_from_dataframe(dataframe=train, x_col=\"image_full_name\", y_col=\"dx\",\n",
        "                                                directory='/content/ham10000-with-one-image-folder/HAM1000_images',\n",
        "                                                shuffle=True,batch_size=32,class_mode=\"categorical\",target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
        "\n",
        "val_data= val_generator.flow_from_dataframe(dataframe=val, x_col=\"image_full_name\", y_col=\"dx\",\n",
        "                                              directory='/content/ham10000-with-one-image-folder/HAM1000_images',\n",
        "                                              shuffle=True,batch_size=32,class_mode='categorical',target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
        "\n",
        "test_data= test_generator.flow_from_dataframe(dataframe=test, x_col=\"image_full_name\", y_col=\"dx\",\n",
        "                                              directory='/content/ham10000-with-one-image-folder/HAM1000_images',\n",
        "                                              shuffle=False,batch_size=1,class_mode=None,target_size=(IMG_WIDTH,IMG_HEIGHT))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6309 validated image filenames belonging to 7 classes.\n",
            "Found 2704 validated image filenames belonging to 7 classes.\n",
            "Found 1002 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WOs0EjX8Ot2",
        "colab_type": "text"
      },
      "source": [
        "# **Focal Loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9H8QLiwJ_rc",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/umbertogriffo/focal-loss-keras\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he4CnLjdH8c5",
        "colab_type": "text"
      },
      "source": [
        "$$\\text{FL}(p_t) = -\\alpha_t (1 - p_t)^{\\gamma} \\, \\text{log}(p_t)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvORsbwy69hO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_focal_loss(gamma=2., alpha=.25):\n",
        "    \"\"\"\n",
        "    Softmax version of focal loss.\n",
        "           m\n",
        "      FL = ∑  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n",
        "          c=1\n",
        "      where m = number of classes, c = class and o = observation\n",
        "    Parameters:\n",
        "      alpha -- the same as weighing factor in balanced cross entropy\n",
        "      gamma -- focusing parameter for modulating factor (1-p)\n",
        "    Default value:\n",
        "      gamma -- 2.0 as mentioned in the paper\n",
        "      alpha -- 0.25 as mentioned in the paper\n",
        "    References:\n",
        "        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n",
        "        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
        "    Usage:\n",
        "     model.compile(loss=[categorical_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
        "    \"\"\"\n",
        "    def categorical_focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        :param y_true: A tensor of the same shape as `y_pred`\n",
        "        :param y_pred: A tensor resulting from a softmax\n",
        "        :return: Output tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        # Scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "\n",
        "        # Clip the prediction value to prevent NaN's and Inf's\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        # Calculate Cross Entropy\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "\n",
        "        # Calculate Focal Loss\n",
        "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
        "\n",
        "        # Compute mean loss in mini_batch\n",
        "        return K.mean(loss, axis=1)\n",
        "\n",
        "    return categorical_focal_loss_fixed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM_7koKYSwRX",
        "colab_type": "text"
      },
      "source": [
        "# Class Weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqppou6MSvrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(name_as_indexes_train), name_as_indexes_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhjJOtHPTOqN",
        "colab_type": "code",
        "outputId": "f454cbf6-86eb-4c0f-bb05-d76be09333fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "class_weights"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.76870748,  2.82534707,  1.32542017, 11.40867993,  1.28939301,\n",
              "        0.21181803, 10.24188312])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoJAN5opTvV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_class_weight_dict = { i : class_weights[i] for i in range(0, len(class_weights) ) }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nM6ctD3Ty8H",
        "colab_type": "code",
        "outputId": "dd0c08a2-f4ab-470b-f954-094cbaf246bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_class_weight_dict"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 4.7687074829931975,\n",
              " 1: 2.825347066726377,\n",
              " 2: 1.3254201680672268,\n",
              " 3: 11.408679927667269,\n",
              " 4: 1.2893930104230533,\n",
              " 5: 0.21181802920933357,\n",
              " 6: 10.241883116883116}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivQqzr9X8T8Z",
        "colab_type": "text"
      },
      "source": [
        "# **Build Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6NKOM5-VHcm",
        "colab_type": "text"
      },
      "source": [
        "### **Use EffNet + fine tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "982Ib3LtLZ19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  base_model = tf.keras.applications.DenseNet121(include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3), weights='imagenet')\n",
        "\n",
        "  average_pooling_layer = GlobalAveragePooling2D()(base_model.output)\n",
        "  \n",
        "  fc_layer = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(average_pooling_layer)\n",
        "  dropout_layer = Dropout(0.25)(fc_layer)\n",
        "  fc_layer = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(dropout_layer)\n",
        "  fc_layer = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  fc_layer = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  fc_layer = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  fc_layer = Dense(16, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  bn_layer = BatchNormalization()(fc_layer)\n",
        "  dropout_layer = Dropout(0.25)(bn_layer)\n",
        "  prediction_layer = Dense(units=7, activation='softmax', name='prediction')(dropout_layer)\n",
        "\n",
        "  for layer in base_model.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  model = Model(inputs=base_model.input, outputs=prediction_layer)\n",
        "  \n",
        "  model.compile(optimizer=Adam(LR), loss=[categorical_focal_loss(alpha=.25, gamma=2)], metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quSBa9F3Qdqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TFNv-FGLdgd",
        "colab_type": "text"
      },
      "source": [
        "### **Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1bAKncT_-0g",
        "colab_type": "code",
        "outputId": "61649dfd-8e58-459d-c3f6-21d4e25828c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1024)         0           relu[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         1049600     global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          131200      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           8256        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           2080        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 32)           1056        dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 16)           528         dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 16)           64          dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 16)           0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 7)            119         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 8,230,407\n",
            "Trainable params: 1,834,279\n",
            "Non-trainable params: 6,396,128\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUkpZH2iO2HT",
        "colab_type": "text"
      },
      "source": [
        "### **Callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W01_QL-DQujb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = '/content/SigFL_DenseNet121_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-TRuxDhSBVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPtUnf9tSCYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnTxHeV9ym7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_plateau = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=.5, min_lr=1-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGLVL4QTSDOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_list = [checkpoint, early_stop, reduce_plateau]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tWxLCM5VFYz",
        "colab_type": "text"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-tzC-r3SEBp",
        "colab_type": "code",
        "outputId": "46e88310-8750-4c67-ec99-06e0094f0444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_data,\n",
        "                    steps_per_epoch=train_data.samples//train_data.batch_size,\n",
        "                    validation_data=val_data,\n",
        "                    validation_steps=val_data.samples//val_data.batch_size,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=cb_list,\n",
        "                    verbose=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.3916 - accuracy: 0.1365\n",
            "Epoch 00001: val_loss improved from -inf to 1.28566, saving model to /content/SigFL_DenseNet121_model.h5\n",
            "197/197 [==============================] - 129s 655ms/step - loss: 1.3916 - accuracy: 0.1365 - val_loss: 1.2857 - val_accuracy: 0.2191 - lr: 3.0000e-05\n",
            "Epoch 2/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.2042 - accuracy: 0.2608\n",
            "Epoch 00002: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 647ms/step - loss: 1.2042 - accuracy: 0.2608 - val_loss: 1.1176 - val_accuracy: 0.4111 - lr: 3.0000e-05\n",
            "Epoch 3/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0504 - accuracy: 0.4010\n",
            "Epoch 00003: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 1.0504 - accuracy: 0.4010 - val_loss: 0.9766 - val_accuracy: 0.5822 - lr: 3.0000e-05\n",
            "Epoch 4/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9250 - accuracy: 0.4816\n",
            "Epoch 00004: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.9250 - accuracy: 0.4816 - val_loss: 0.8595 - val_accuracy: 0.6592 - lr: 3.0000e-05\n",
            "Epoch 5/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.8195 - accuracy: 0.5289\n",
            "Epoch 00005: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.8195 - accuracy: 0.5289 - val_loss: 0.7636 - val_accuracy: 0.6734 - lr: 3.0000e-05\n",
            "Epoch 6/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.7298 - accuracy: 0.5656\n",
            "Epoch 00006: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.7298 - accuracy: 0.5656 - val_loss: 0.6873 - val_accuracy: 0.6484 - lr: 3.0000e-05\n",
            "Epoch 7/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.6025\n",
            "Epoch 00007: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.6533 - accuracy: 0.6025 - val_loss: 0.6134 - val_accuracy: 0.6879 - lr: 3.0000e-05\n",
            "Epoch 8/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.5885 - accuracy: 0.6248\n",
            "Epoch 00008: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.5885 - accuracy: 0.6248 - val_loss: 0.5520 - val_accuracy: 0.7199 - lr: 3.0000e-05\n",
            "Epoch 9/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.6436\n",
            "Epoch 00009: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 128s 648ms/step - loss: 0.5320 - accuracy: 0.6436 - val_loss: 0.5005 - val_accuracy: 0.7139 - lr: 3.0000e-05\n",
            "Epoch 10/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.4835 - accuracy: 0.6588\n",
            "Epoch 00010: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 643ms/step - loss: 0.4835 - accuracy: 0.6588 - val_loss: 0.4571 - val_accuracy: 0.7031 - lr: 3.0000e-05\n",
            "Epoch 11/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.6659\n",
            "Epoch 00011: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.4410 - accuracy: 0.6659 - val_loss: 0.4152 - val_accuracy: 0.7254 - lr: 3.0000e-05\n",
            "Epoch 12/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.6771\n",
            "Epoch 00012: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.4036 - accuracy: 0.6771 - val_loss: 0.3814 - val_accuracy: 0.7236 - lr: 3.0000e-05\n",
            "Epoch 13/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3693 - accuracy: 0.6948\n",
            "Epoch 00013: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.3693 - accuracy: 0.6948 - val_loss: 0.3506 - val_accuracy: 0.7258 - lr: 3.0000e-05\n",
            "Epoch 14/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3398 - accuracy: 0.6968\n",
            "Epoch 00014: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 128s 647ms/step - loss: 0.3398 - accuracy: 0.6968 - val_loss: 0.3203 - val_accuracy: 0.7440 - lr: 3.0000e-05\n",
            "Epoch 15/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.7050\n",
            "Epoch 00015: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.3132 - accuracy: 0.7050 - val_loss: 0.2962 - val_accuracy: 0.7470 - lr: 3.0000e-05\n",
            "Epoch 16/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2884 - accuracy: 0.7190\n",
            "Epoch 00016: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.2884 - accuracy: 0.7190 - val_loss: 0.2745 - val_accuracy: 0.7448 - lr: 3.0000e-05\n",
            "Epoch 17/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2663 - accuracy: 0.7238\n",
            "Epoch 00017: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.2663 - accuracy: 0.7238 - val_loss: 0.2523 - val_accuracy: 0.7578 - lr: 3.0000e-05\n",
            "Epoch 18/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.7304\n",
            "Epoch 00018: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.2471 - accuracy: 0.7304 - val_loss: 0.2367 - val_accuracy: 0.7392 - lr: 3.0000e-05\n",
            "Epoch 19/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.7273\n",
            "Epoch 00019: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 647ms/step - loss: 0.2289 - accuracy: 0.7273 - val_loss: 0.2205 - val_accuracy: 0.7243 - lr: 3.0000e-05\n",
            "Epoch 20/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.7349\n",
            "Epoch 00020: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 643ms/step - loss: 0.2127 - accuracy: 0.7349 - val_loss: 0.2014 - val_accuracy: 0.7586 - lr: 3.0000e-05\n",
            "Epoch 21/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.7381\n",
            "Epoch 00021: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1977 - accuracy: 0.7381 - val_loss: 0.1867 - val_accuracy: 0.7679 - lr: 3.0000e-05\n",
            "Epoch 22/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.7394\n",
            "Epoch 00022: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.1842 - accuracy: 0.7394 - val_loss: 0.1745 - val_accuracy: 0.7701 - lr: 3.0000e-05\n",
            "Epoch 23/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.7499\n",
            "Epoch 00023: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.1714 - accuracy: 0.7499 - val_loss: 0.1623 - val_accuracy: 0.7693 - lr: 3.0000e-05\n",
            "Epoch 24/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1602 - accuracy: 0.7496\n",
            "Epoch 00024: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1602 - accuracy: 0.7496 - val_loss: 0.1558 - val_accuracy: 0.7392 - lr: 3.0000e-05\n",
            "Epoch 25/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.7464\n",
            "Epoch 00025: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1494 - accuracy: 0.7464 - val_loss: 0.1422 - val_accuracy: 0.7682 - lr: 3.0000e-05\n",
            "Epoch 26/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.7521\n",
            "Epoch 00026: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1423 - accuracy: 0.7521 - val_loss: 0.1371 - val_accuracy: 0.7749 - lr: 1.5000e-05\n",
            "Epoch 27/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.7599\n",
            "Epoch 00027: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.1368 - accuracy: 0.7599 - val_loss: 0.1325 - val_accuracy: 0.7723 - lr: 1.5000e-05\n",
            "Epoch 28/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.7610\n",
            "Epoch 00028: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1325 - accuracy: 0.7610 - val_loss: 0.1297 - val_accuracy: 0.7653 - lr: 1.5000e-05\n",
            "Epoch 29/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.7668\n",
            "Epoch 00029: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 7.499999810534064e-06.\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.1277 - accuracy: 0.7668 - val_loss: 0.1243 - val_accuracy: 0.7675 - lr: 1.5000e-05\n",
            "Epoch 30/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.7649\n",
            "Epoch 00030: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.1246 - accuracy: 0.7649 - val_loss: 0.1218 - val_accuracy: 0.7794 - lr: 7.5000e-06\n",
            "Epoch 31/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.7642\n",
            "Epoch 00031: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1222 - accuracy: 0.7642 - val_loss: 0.1204 - val_accuracy: 0.7682 - lr: 7.5000e-06\n",
            "Epoch 32/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.7715\n",
            "Epoch 00032: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.1202 - accuracy: 0.7715 - val_loss: 0.1176 - val_accuracy: 0.7783 - lr: 7.5000e-06\n",
            "Epoch 33/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.7746\n",
            "Epoch 00033: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.749999905267032e-06.\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1177 - accuracy: 0.7746 - val_loss: 0.1170 - val_accuracy: 0.7656 - lr: 7.5000e-06\n",
            "Epoch 34/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.7692\n",
            "Epoch 00034: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1169 - accuracy: 0.7692 - val_loss: 0.1150 - val_accuracy: 0.7719 - lr: 3.7500e-06\n",
            "Epoch 35/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.7739\n",
            "Epoch 00035: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.1154 - accuracy: 0.7739 - val_loss: 0.1139 - val_accuracy: 0.7775 - lr: 3.7500e-06\n",
            "Epoch 36/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.7794\n",
            "Epoch 00036: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.874999952633516e-06.\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1140 - accuracy: 0.7794 - val_loss: 0.1133 - val_accuracy: 0.7738 - lr: 3.7500e-06\n",
            "Epoch 37/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.7730\n",
            "Epoch 00037: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.1138 - accuracy: 0.7730 - val_loss: 0.1126 - val_accuracy: 0.7727 - lr: 1.8750e-06\n",
            "Epoch 38/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.7723\n",
            "Epoch 00038: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 128s 649ms/step - loss: 0.1133 - accuracy: 0.7723 - val_loss: 0.1122 - val_accuracy: 0.7723 - lr: 1.8750e-06\n",
            "Epoch 39/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.7725\n",
            "Epoch 00039: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.37499976316758e-07.\n",
            "197/197 [==============================] - 127s 647ms/step - loss: 0.1128 - accuracy: 0.7725 - val_loss: 0.1116 - val_accuracy: 0.7746 - lr: 1.8750e-06\n",
            "Epoch 40/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.7819\n",
            "Epoch 00040: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1121 - accuracy: 0.7819 - val_loss: 0.1112 - val_accuracy: 0.7757 - lr: 9.3750e-07\n",
            "Epoch 41/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.7739\n",
            "Epoch 00041: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1118 - accuracy: 0.7739 - val_loss: 0.1109 - val_accuracy: 0.7753 - lr: 9.3750e-07\n",
            "Epoch 42/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.7765\n",
            "Epoch 00042: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 4.68749988158379e-07.\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.1117 - accuracy: 0.7765 - val_loss: 0.1108 - val_accuracy: 0.7746 - lr: 9.3750e-07\n",
            "Epoch 43/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.7749\n",
            "Epoch 00043: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1115 - accuracy: 0.7749 - val_loss: 0.1107 - val_accuracy: 0.7746 - lr: 4.6875e-07\n",
            "Epoch 44/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.7824\n",
            "Epoch 00044: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 643ms/step - loss: 0.1110 - accuracy: 0.7824 - val_loss: 0.1106 - val_accuracy: 0.7731 - lr: 4.6875e-07\n",
            "Epoch 45/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.7730\n",
            "Epoch 00045: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.343749940791895e-07.\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1109 - accuracy: 0.7730 - val_loss: 0.1103 - val_accuracy: 0.7760 - lr: 4.6875e-07\n",
            "Epoch 46/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.7715\n",
            "Epoch 00046: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1113 - accuracy: 0.7715 - val_loss: 0.1103 - val_accuracy: 0.7753 - lr: 2.3437e-07\n",
            "Epoch 47/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.7766\n",
            "Epoch 00047: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 644ms/step - loss: 0.1109 - accuracy: 0.7766 - val_loss: 0.1102 - val_accuracy: 0.7764 - lr: 2.3437e-07\n",
            "Epoch 48/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.7715\n",
            "Epoch 00048: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.1718749703959475e-07.\n",
            "197/197 [==============================] - 127s 647ms/step - loss: 0.1112 - accuracy: 0.7715 - val_loss: 0.1103 - val_accuracy: 0.7742 - lr: 2.3437e-07\n",
            "Epoch 49/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.7757\n",
            "Epoch 00049: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1107 - accuracy: 0.7757 - val_loss: 0.1100 - val_accuracy: 0.7757 - lr: 1.1719e-07\n",
            "Epoch 50/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.7763\n",
            "Epoch 00050: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1110 - accuracy: 0.7763 - val_loss: 0.1100 - val_accuracy: 0.7746 - lr: 1.1719e-07\n",
            "Epoch 51/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.7770\n",
            "Epoch 00051: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 5.859374851979737e-08.\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1109 - accuracy: 0.7770 - val_loss: 0.1100 - val_accuracy: 0.7727 - lr: 1.1719e-07\n",
            "Epoch 52/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.7776\n",
            "Epoch 00052: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 645ms/step - loss: 0.1109 - accuracy: 0.7776 - val_loss: 0.1102 - val_accuracy: 0.7723 - lr: 5.8594e-08\n",
            "Epoch 53/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.7770\n",
            "Epoch 00053: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 647ms/step - loss: 0.1109 - accuracy: 0.7770 - val_loss: 0.1101 - val_accuracy: 0.7749 - lr: 5.8594e-08\n",
            "Epoch 54/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.7749\n",
            "Epoch 00054: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 2.9296874259898686e-08.\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1107 - accuracy: 0.7749 - val_loss: 0.1101 - val_accuracy: 0.7749 - lr: 5.8594e-08\n",
            "Epoch 55/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.7743\n",
            "Epoch 00055: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 647ms/step - loss: 0.1111 - accuracy: 0.7743 - val_loss: 0.1101 - val_accuracy: 0.7746 - lr: 2.9297e-08\n",
            "Epoch 56/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.7744\n",
            "Epoch 00056: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1106 - accuracy: 0.7744 - val_loss: 0.1099 - val_accuracy: 0.7742 - lr: 2.9297e-08\n",
            "Epoch 57/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.7701\n",
            "Epoch 00057: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.4648437129949343e-08.\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1108 - accuracy: 0.7701 - val_loss: 0.1099 - val_accuracy: 0.7760 - lr: 2.9297e-08\n",
            "Epoch 58/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.7698\n",
            "Epoch 00058: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 647ms/step - loss: 0.1107 - accuracy: 0.7698 - val_loss: 0.1100 - val_accuracy: 0.7757 - lr: 1.4648e-08\n",
            "Epoch 59/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.7708\n",
            "Epoch 00059: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 646ms/step - loss: 0.1108 - accuracy: 0.7708 - val_loss: 0.1100 - val_accuracy: 0.7734 - lr: 1.4648e-08\n",
            "Epoch 60/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.7739\n",
            "Epoch 00060: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00060: ReduceLROnPlateau reducing learning rate to 7.324218564974672e-09.\n",
            "197/197 [==============================] - 128s 648ms/step - loss: 0.1109 - accuracy: 0.7739 - val_loss: 0.1100 - val_accuracy: 0.7757 - lr: 1.4648e-08\n",
            "Epoch 61/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.7690\n",
            "Epoch 00061: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 127s 647ms/step - loss: 0.1111 - accuracy: 0.7690 - val_loss: 0.1100 - val_accuracy: 0.7753 - lr: 7.3242e-09\n",
            "Epoch 62/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.7751\n",
            "Epoch 00062: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 128s 647ms/step - loss: 0.1109 - accuracy: 0.7751 - val_loss: 0.1100 - val_accuracy: 0.7749 - lr: 7.3242e-09\n",
            "Epoch 63/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.7800\n",
            "Epoch 00063: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 3.662109282487336e-09.\n",
            "197/197 [==============================] - 127s 647ms/step - loss: 0.1106 - accuracy: 0.7800 - val_loss: 0.1099 - val_accuracy: 0.7768 - lr: 7.3242e-09\n",
            "Epoch 64/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.7744\n",
            "Epoch 00064: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 129s 655ms/step - loss: 0.1109 - accuracy: 0.7744 - val_loss: 0.1099 - val_accuracy: 0.7760 - lr: 3.6621e-09\n",
            "Epoch 65/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.7674\n",
            "Epoch 00065: val_loss did not improve from 1.28566\n",
            "197/197 [==============================] - 128s 650ms/step - loss: 0.1110 - accuracy: 0.7674 - val_loss: 0.1099 - val_accuracy: 0.7772 - lr: 3.6621e-09\n",
            "Epoch 66/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.7714\n",
            "Epoch 00066: val_loss did not improve from 1.28566\n",
            "\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.831054641243668e-09.\n",
            "197/197 [==============================] - 128s 647ms/step - loss: 0.1109 - accuracy: 0.7714 - val_loss: 0.1099 - val_accuracy: 0.7753 - lr: 3.6621e-09\n",
            "Epoch 00066: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "383eb86x9FvQ",
        "colab_type": "text"
      },
      "source": [
        "# **Accuracy and Loss Graph**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKv_2jc7O4Se",
        "colab_type": "text"
      },
      "source": [
        "### **Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtDoga8c10Ly",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "cd1c9e12-0c57-4169-ed40-67ab75aa2fe3"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.title('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6pg2k6xO5p8",
        "colab_type": "text"
      },
      "source": [
        "### **Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT1Pr5RmWJkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "50ee7492-cc82-4a84-a4d7-296d917f304e"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.title('loss')\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1cWi7orKdUr",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ea-ST316j3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2a82e3a5-57b9-4cd5-bba2-99c0f2523ab7"
      },
      "source": [
        "test_data.reset()\n",
        "predictions = model.predict_generator(test_data, steps=test_data.samples/test_data.batch_size,verbose=1)\n",
        "y_pred= np.argmax(predictions, axis=1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-99bdc2a40673>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n",
            "1002/1002 [==============================] - 12s 12ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJfzBH2gcQ5M",
        "colab_type": "text"
      },
      "source": [
        "### **Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDJVF1dbWQlu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "4fa9568d-b610-4e06-f07a-c8e7bafdf962"
      },
      "source": [
        "Y_pred = predictions\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(name_as_indexes_test, y_pred))\n",
        "print('Classification Report')\n",
        "classes_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "print(classification_report(name_as_indexes_test, y_pred, target_names=classes_names))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[  5   9  16   0   3   8   0]\n",
            " [  2  24  18   0   2   1   0]\n",
            " [  2   8  74   0   8  33   0]\n",
            " [  1   1   6   0   2   5   0]\n",
            " [  2   2  27   0  51  28   0]\n",
            " [  0   4  30   0  18 597   0]\n",
            " [  0  11   1   0   1   2   0]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.42      0.12      0.19        41\n",
            "         bcc       0.41      0.51      0.45        47\n",
            "         bkl       0.43      0.59      0.50       125\n",
            "          df       0.00      0.00      0.00        15\n",
            "         mel       0.60      0.46      0.52       110\n",
            "          nv       0.89      0.92      0.90       649\n",
            "        vasc       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.75      1002\n",
            "   macro avg       0.39      0.37      0.37      1002\n",
            "weighted avg       0.73      0.75      0.73      1002\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMxOe1qPcUSr",
        "colab_type": "text"
      },
      "source": [
        "### **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWSBDzE5WXgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "fad9e2b1-86ed-40e0-cccb-1a025d6c0c4d"
      },
      "source": [
        "cm = (confusion_matrix(name_as_indexes_test, y_pred))\n",
        "\n",
        "plot_confusion_matrix(cm, classes_names)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[  5   9  16   0   3   8   0]\n",
            " [  2  24  18   0   2   1   0]\n",
            " [  2   8  74   0   8  33   0]\n",
            " [  1   1   6   0   2   5   0]\n",
            " [  2   2  27   0  51  28   0]\n",
            " [  0   4  30   0  18 597   0]\n",
            " [  0  11   1   0   1   2   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbXcAwdJ-1tX",
        "colab_type": "text"
      },
      "source": [
        "### **Sensitivity & Specificity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH-wStPm6T7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = sum(sum(cm))\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc7FeOe56a9-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f3e17b3b-875b-4952-d462-73a24c744852"
      },
      "source": [
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sensitivity: 0.3571\n",
            "specificity: 0.9231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkrPLbkZdva9",
        "colab_type": "text"
      },
      "source": [
        "# **Grad-CAM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_OVC2F8xfR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_conv2d = 'conv5_block16_2_conv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyWQAabav_ST",
        "colab_type": "text"
      },
      "source": [
        "### **AKIEC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5JjxhIrqN5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "akiec_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0026492.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGMmNOxxiHxq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "8d6cdb43-35b6-40d0-b5bc-e1dae4cbff49"
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, akiec_img, layer_name=last_conv2d)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model prediction:\n",
            "\tmel            \t(4)\twith probability 0.590\n",
            "\takiec          \t(0)\twith probability 0.297\n",
            "\tbkl            \t(2)\twith probability 0.055\n",
            "\tvasc           \t(6)\twith probability 0.027\n",
            "\tdf             \t(3)\twith probability 0.015\n",
            "Explanation for 'mel'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-c01fefc2e1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradcam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguided_gradcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_saliency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0makiec_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_conv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/ham10000_utils_functions.py\u001b[0m in \u001b[0;36mcompute_saliency\u001b[0;34m(model, guided_model, img_path, layer_name, cls, visualize, save)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_decode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Explanation for '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mgradcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguided_backprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguided_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mguided_gradcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradcam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ham10000_utils_functions.py\u001b[0m in \u001b[0;36mgrad_cam\u001b[0;34m(input_model, image, cls, layer_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0my_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mconv_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Normalize if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# grads = normalize(grads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients_v2\u001b[0;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    303\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    489\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    492\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    493\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D53Hg3-mwNj-",
        "colab_type": "text"
      },
      "source": [
        "### **BCC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-APRYghPa4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bcc_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0024332.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IavEoR0qwWO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, bcc_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnzfOod3xC7p",
        "colab_type": "text"
      },
      "source": [
        "### **BKL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Za1Ztu0kxVpc",
        "colab": {}
      },
      "source": [
        "bkl_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0025548.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xc_tDIcsxVpg",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, bkl_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2qr1BF9xEnD",
        "colab_type": "text"
      },
      "source": [
        "### **DF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w3400LGvxWEF",
        "colab": {}
      },
      "source": [
        "df_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0033626.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S92MquPFxWEI",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, df_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y6JOyRWxJy7",
        "colab_type": "text"
      },
      "source": [
        "### **MEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9mRW-epcxWdq",
        "colab": {}
      },
      "source": [
        "mel_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0024516.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g4j2KO_pxWdv",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, mel_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKEm-_WKxHRq",
        "colab_type": "text"
      },
      "source": [
        "### **NV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "opRTYW5SxXgR",
        "colab": {}
      },
      "source": [
        "nv_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0024349.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iVbqIHvGxXgV",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, nv_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVFPRGL0xHtK",
        "colab_type": "text"
      },
      "source": [
        "### **VASC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YuzSPvQ9xXJg",
        "colab": {}
      },
      "source": [
        "vasc_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0025452.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ol1Ik8qDxXJj",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, vasc_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYJYt3yOB47l",
        "colab_type": "text"
      },
      "source": [
        "# **Download Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFv5jXItB-fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuVkAwOn3A9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('/content/Focal-Loss_ResNet50_model.h5')\n",
        "files.download('/content/Focal-Loss_ResNet50_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}