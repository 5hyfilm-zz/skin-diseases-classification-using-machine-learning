{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SigFocal_DenseNet121_CAM_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNBiTAXvDiR12596n6Q4pRU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filmerxyz/JSTP-22_SkinDiseaseClassificationUsingMachineLearning/blob/master/SigFocal_DenseNet121_CAM_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGAbDjt3rz_5",
        "colab_type": "text"
      },
      "source": [
        "# **Check GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KeAnM3PXlUe",
        "colab_type": "code",
        "outputId": "d39efbdd-aa61-40c6-f17b-c9fcbe6dc5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May 30 19:15:14 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    38W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QrrDycMRWp7",
        "colab_type": "code",
        "outputId": "43b9af91-49d5-487f-a25c-4338ccb50d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install runai"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: runai in /usr/local/lib/python3.6/dist-packages (0.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbD3Qq816yZZ",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tch5If72HQeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from os.path import join\n",
        "\n",
        "from ham10000_utils_functions import plot_confusion_matrix, normalize, deprocess_image, my_decode_predictions, guided_backprop, grad_cam, compute_saliency"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPwDTos761Oq",
        "colab_type": "text"
      },
      "source": [
        "# **Clone Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHjfNRvqza-U",
        "colab_type": "code",
        "outputId": "1842e158-5b0f-43e1-b629-3c208ca34239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/EvilPickle-PCSHSPT/ham10000-with-one-image-folder"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ham10000-with-one-image-folder' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__IXKxBZVymL",
        "colab_type": "text"
      },
      "source": [
        "# **Constant Variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ2LKSeHQRnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 7\n",
        "STEPS = 16\n",
        "\n",
        "LR = 3e-5 # Learning rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrpBmL7mVlJC",
        "colab_type": "text"
      },
      "source": [
        "# **Prepare Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnsBJBcPL3SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('/content/ham10000-with-one-image-folder/HAM10000_metadata.csv')\n",
        "data['image_full_name']=data['image_id']+'.jpg'\n",
        "X=data[['image_full_name','dx','lesion_id']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rt4v6YTM0Fr",
        "colab_type": "code",
        "outputId": "d59f87d4-c3a7-4810-805b-f1ad52ef5afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>image_full_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0027419.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0025030.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0026769.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0025661.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>ISIC_0031633.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx  ...   sex  localization   image_full_name\n",
              "0  HAM_0000118  ISIC_0027419  bkl  ...  male         scalp  ISIC_0027419.jpg\n",
              "1  HAM_0000118  ISIC_0025030  bkl  ...  male         scalp  ISIC_0025030.jpg\n",
              "2  HAM_0002730  ISIC_0026769  bkl  ...  male         scalp  ISIC_0026769.jpg\n",
              "3  HAM_0002730  ISIC_0025661  bkl  ...  male         scalp  ISIC_0025661.jpg\n",
              "4  HAM_0001466  ISIC_0031633  bkl  ...  male           ear  ISIC_0031633.jpg\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_1JsUvHGMGi",
        "colab_type": "text"
      },
      "source": [
        "### **Split Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1q1WsAhM-HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Y=X.pop('dx').to_frame()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ghodz0zOJ0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.concat([X_train,y_train],axis=1)\n",
        "val = pd.concat([X_val,y_val],axis=1)\n",
        "test = pd.concat([X_test,y_test],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG6iaiiyMHmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train['dx'])\n",
        "name_as_indexes_train = encoder.transform(train['dx']) \n",
        "train['label'] = name_as_indexes_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLryd9huOStO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(val['dx'])\n",
        "name_as_indexes_val = encoder.transform(val['dx']) \n",
        "val['label'] = name_as_indexes_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VYdnvBOOUek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder=LabelEncoder()\n",
        "encoder.fit(test['dx'])\n",
        "name_as_indexes_test = encoder.transform(test['dx']) \n",
        "test['label'] = name_as_indexes_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDOtGZx7YiJa",
        "colab_type": "text"
      },
      "source": [
        "### **Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6snNZRZOWaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = ImageDataGenerator(rescale = 1./255,\n",
        "                                     rotation_range=360,  \n",
        "                                     zoom_range = 0.3,\n",
        "                                     horizontal_flip=True,\n",
        "                                     vertical_flip=True,\n",
        "                                     fill_mode='reflect')\n",
        "                                    \n",
        "test_generator=ImageDataGenerator(rescale = 1./255)\n",
        "test_generator=ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdF3KvYwOfC5",
        "colab_type": "code",
        "outputId": "28869355-9456-4af6-8646-5f17c0922ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_data= train_generator.flow_from_dataframe(dataframe=train,x_col=\"image_full_name\",y_col=\"dx\",\n",
        "                                                directory='/content/ham10000-with-one-image-folder/HAM1000_images',\n",
        "                                                shuffle=True,batch_size=32,class_mode=\"categorical\",target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
        "\n",
        "val_data= test_generator.flow_from_dataframe(dataframe=val,x_col=\"image_full_name\",y_col=\"dx\",\n",
        "                                              directory='/content/ham10000-with-one-image-folder/HAM1000_images',\n",
        "                                              shuffle=True,batch_size=32,class_mode='categorical',target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
        "\n",
        "test_data= test_generator.flow_from_dataframe(dataframe=test,x_col=\"image_full_name\",y_col=\"dx\",\n",
        "                                              directory='/content/ham10000-with-one-image-folder/HAM1000_images',\n",
        "                                              shuffle=False,batch_size=1,class_mode=None,target_size=(IMG_WIDTH,IMG_HEIGHT))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6309 validated image filenames belonging to 7 classes.\n",
            "Found 2704 validated image filenames belonging to 7 classes.\n",
            "Found 1002 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WOs0EjX8Ot2",
        "colab_type": "text"
      },
      "source": [
        "# **Focal Loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9H8QLiwJ_rc",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/mkocabas/focal-loss-keras\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he4CnLjdH8c5",
        "colab_type": "text"
      },
      "source": [
        "$$\\text{FL}(p_t) = -\\alpha_t (1 - p_t)^{\\gamma} \\, \\text{log}(p_t)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHu6edXfTaAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def focal_loss(gamma=2., alpha=0.5):\n",
        "\tdef focal_loss_fixed(y_true, y_pred):\n",
        "\t\tpt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "\t\tpt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "\t\treturn -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
        "\treturn focal_loss_fixed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM_7koKYSwRX",
        "colab_type": "text"
      },
      "source": [
        "# Class Weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqppou6MSvrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(name_as_indexes_train), name_as_indexes_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhjJOtHPTOqN",
        "colab_type": "code",
        "outputId": "d4d9f597-f608-453d-b40c-294e1d178fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "class_weights"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.76870748,  2.82534707,  1.32542017, 11.40867993,  1.28939301,\n",
              "        0.21181803, 10.24188312])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoJAN5opTvV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_class_weight_dict = { i : class_weights[i] for i in range(0, len(class_weights) ) }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nM6ctD3Ty8H",
        "colab_type": "code",
        "outputId": "53e26022-4b02-43ee-9ab4-6c7d6e094c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_class_weight_dict"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 4.7687074829931975,\n",
              " 1: 2.825347066726377,\n",
              " 2: 1.3254201680672268,\n",
              " 3: 11.408679927667269,\n",
              " 4: 1.2893930104230533,\n",
              " 5: 0.21181802920933357,\n",
              " 6: 10.241883116883116}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivQqzr9X8T8Z",
        "colab_type": "text"
      },
      "source": [
        "# **Build Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6NKOM5-VHcm",
        "colab_type": "text"
      },
      "source": [
        "### **Use DenseNet121 + fine tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "982Ib3LtLZ19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  base_model = tf.keras.applications.DenseNet121(include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3), weights='imagenet')\n",
        "  \n",
        "  for layer in base_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "  average_pooling_layer = GlobalAveragePooling2D()(base_model.output)\n",
        "  \n",
        "  fc_layer = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(average_pooling_layer)\n",
        "  fc_layer = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  fc_layer = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  fc_layer = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  fc_layer = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  bn_layer = BatchNormalization()(fc_layer)\n",
        "  dropout_layer = Dropout(0.25)(bn_layer)\n",
        "  prediction_layer = Dense(units=7, activation='softmax', name='prediction')(dropout_layer)\n",
        "  model = Model(inputs=base_model.input, outputs=prediction_layer)\n",
        "  \n",
        "  model.compile(optimizer=Adam(LR), loss=tfa.losses.sigmoid_focal_crossentropy, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quSBa9F3Qdqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TFNv-FGLdgd",
        "colab_type": "text"
      },
      "source": [
        "### **Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1bAKncT_-0g",
        "colab_type": "code",
        "outputId": "11f2bf4c-7724-4b2b-c10f-0e6b88d1daf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1024)         0           relu[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          524800      global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          131328      dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 32)           2080        dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32)           128         dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32)           0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 7)            231         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,737,223\n",
            "Trainable params: 783,303\n",
            "Non-trainable params: 6,953,920\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUkpZH2iO2HT",
        "colab_type": "text"
      },
      "source": [
        "### **Callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W01_QL-DQujb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = '/content/Acc_Focal-Loss_ResNet50_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-TRuxDhSBVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPtUnf9tSCYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnTxHeV9ym7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_plateau = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=.5, min_lr=1-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGLVL4QTSDOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_list = [checkpoint, early_stop, reduce_plateau]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tWxLCM5VFYz",
        "colab_type": "text"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-tzC-r3SEBp",
        "colab_type": "code",
        "outputId": "0c19c0b5-ade0-460c-915b-abbedbd41d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(generator=train_data,\n",
        "                            steps_per_epoch=train_data.samples//train_data.batch_size,\n",
        "                            validation_data=val_data,\n",
        "                            verbose=1,\n",
        "                            validation_steps=val_data.samples//val_data.batch_size,\n",
        "                            epochs=EPOCHS,\n",
        "                            class_weight=train_class_weight_dict,\n",
        "                            callbacks=cb_list)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-28-bf4f2b01f2b5>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.7892 - accuracy: 0.1160\n",
            "Epoch 00001: val_loss improved from -inf to 1.66363, saving model to /content/Acc_Focal-Loss_ResNet50_model.h5\n",
            "197/197 [==============================] - 133s 675ms/step - loss: 1.7892 - accuracy: 0.1160 - val_loss: 1.6636 - val_accuracy: 0.1135 - lr: 3.0000e-05\n",
            "Epoch 2/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.6252 - accuracy: 0.1502\n",
            "Epoch 00002: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 131s 664ms/step - loss: 1.6252 - accuracy: 0.1502 - val_loss: 1.5461 - val_accuracy: 0.2619 - lr: 3.0000e-05\n",
            "Epoch 3/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.5349 - accuracy: 0.1721\n",
            "Epoch 00003: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 131s 663ms/step - loss: 1.5349 - accuracy: 0.1721 - val_loss: 1.5315 - val_accuracy: 0.2221 - lr: 3.0000e-05\n",
            "Epoch 4/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.4724 - accuracy: 0.2063\n",
            "Epoch 00004: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 660ms/step - loss: 1.4724 - accuracy: 0.2063 - val_loss: 1.4694 - val_accuracy: 0.2664 - lr: 3.0000e-05\n",
            "Epoch 5/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.4090 - accuracy: 0.2324\n",
            "Epoch 00005: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 659ms/step - loss: 1.4090 - accuracy: 0.2324 - val_loss: 1.4140 - val_accuracy: 0.3114 - lr: 3.0000e-05\n",
            "Epoch 6/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.3647 - accuracy: 0.2492\n",
            "Epoch 00006: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 655ms/step - loss: 1.3647 - accuracy: 0.2492 - val_loss: 1.3629 - val_accuracy: 0.3441 - lr: 3.0000e-05\n",
            "Epoch 7/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.3267 - accuracy: 0.2555\n",
            "Epoch 00007: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 654ms/step - loss: 1.3267 - accuracy: 0.2555 - val_loss: 1.3526 - val_accuracy: 0.3367 - lr: 3.0000e-05\n",
            "Epoch 8/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.2871 - accuracy: 0.2834\n",
            "Epoch 00008: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 656ms/step - loss: 1.2871 - accuracy: 0.2834 - val_loss: 1.2867 - val_accuracy: 0.4070 - lr: 3.0000e-05\n",
            "Epoch 9/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.2547 - accuracy: 0.3110\n",
            "Epoch 00009: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 653ms/step - loss: 1.2547 - accuracy: 0.3110 - val_loss: 1.2616 - val_accuracy: 0.4237 - lr: 3.0000e-05\n",
            "Epoch 10/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.2343 - accuracy: 0.3057\n",
            "Epoch 00010: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 653ms/step - loss: 1.2343 - accuracy: 0.3057 - val_loss: 1.2308 - val_accuracy: 0.4412 - lr: 3.0000e-05\n",
            "Epoch 11/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.2020 - accuracy: 0.3161\n",
            "Epoch 00011: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 128s 652ms/step - loss: 1.2020 - accuracy: 0.3161 - val_loss: 1.2129 - val_accuracy: 0.4438 - lr: 3.0000e-05\n",
            "Epoch 12/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.1788 - accuracy: 0.3478\n",
            "Epoch 00012: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 653ms/step - loss: 1.1788 - accuracy: 0.3478 - val_loss: 1.2263 - val_accuracy: 0.3925 - lr: 3.0000e-05\n",
            "Epoch 13/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.1588 - accuracy: 0.3573\n",
            "Epoch 00013: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 128s 652ms/step - loss: 1.1588 - accuracy: 0.3573 - val_loss: 1.2106 - val_accuracy: 0.4096 - lr: 3.0000e-05\n",
            "Epoch 14/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.1439 - accuracy: 0.3658\n",
            "Epoch 00014: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 653ms/step - loss: 1.1439 - accuracy: 0.3658 - val_loss: 1.1684 - val_accuracy: 0.4468 - lr: 3.0000e-05\n",
            "Epoch 15/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.1306 - accuracy: 0.3793\n",
            "Epoch 00015: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 655ms/step - loss: 1.1306 - accuracy: 0.3793 - val_loss: 1.1687 - val_accuracy: 0.4386 - lr: 3.0000e-05\n",
            "Epoch 16/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.1060 - accuracy: 0.3898\n",
            "Epoch 00016: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 656ms/step - loss: 1.1060 - accuracy: 0.3898 - val_loss: 1.1107 - val_accuracy: 0.5346 - lr: 3.0000e-05\n",
            "Epoch 17/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0931 - accuracy: 0.4088\n",
            "Epoch 00017: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 658ms/step - loss: 1.0931 - accuracy: 0.4088 - val_loss: 1.1215 - val_accuracy: 0.5011 - lr: 3.0000e-05\n",
            "Epoch 18/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0773 - accuracy: 0.4198\n",
            "Epoch 00018: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 657ms/step - loss: 1.0773 - accuracy: 0.4198 - val_loss: 1.1311 - val_accuracy: 0.4554 - lr: 3.0000e-05\n",
            "Epoch 19/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0625 - accuracy: 0.4220\n",
            "Epoch 00019: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.4999999621068127e-05.\n",
            "197/197 [==============================] - 129s 656ms/step - loss: 1.0625 - accuracy: 0.4220 - val_loss: 1.1513 - val_accuracy: 0.4096 - lr: 3.0000e-05\n",
            "Epoch 20/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0457 - accuracy: 0.4274\n",
            "Epoch 00020: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 656ms/step - loss: 1.0457 - accuracy: 0.4274 - val_loss: 1.0901 - val_accuracy: 0.4967 - lr: 1.5000e-05\n",
            "Epoch 21/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0424 - accuracy: 0.4344\n",
            "Epoch 00021: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 655ms/step - loss: 1.0424 - accuracy: 0.4344 - val_loss: 1.0731 - val_accuracy: 0.5190 - lr: 1.5000e-05\n",
            "Epoch 22/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0322 - accuracy: 0.4351\n",
            "Epoch 00022: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 7.499999810534064e-06.\n",
            "197/197 [==============================] - 130s 657ms/step - loss: 1.0322 - accuracy: 0.4351 - val_loss: 1.0910 - val_accuracy: 0.4877 - lr: 1.5000e-05\n",
            "Epoch 23/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0304 - accuracy: 0.4410\n",
            "Epoch 00023: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 658ms/step - loss: 1.0304 - accuracy: 0.4410 - val_loss: 1.0703 - val_accuracy: 0.5190 - lr: 7.5000e-06\n",
            "Epoch 24/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0226 - accuracy: 0.4477\n",
            "Epoch 00024: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 657ms/step - loss: 1.0226 - accuracy: 0.4477 - val_loss: 1.0592 - val_accuracy: 0.5301 - lr: 7.5000e-06\n",
            "Epoch 25/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0170 - accuracy: 0.4607\n",
            "Epoch 00025: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.749999905267032e-06.\n",
            "197/197 [==============================] - 130s 658ms/step - loss: 1.0170 - accuracy: 0.4607 - val_loss: 1.0651 - val_accuracy: 0.5298 - lr: 7.5000e-06\n",
            "Epoch 26/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0079 - accuracy: 0.4593\n",
            "Epoch 00026: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 658ms/step - loss: 1.0079 - accuracy: 0.4593 - val_loss: 1.0571 - val_accuracy: 0.5365 - lr: 3.7500e-06\n",
            "Epoch 27/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0084 - accuracy: 0.4604\n",
            "Epoch 00027: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 660ms/step - loss: 1.0084 - accuracy: 0.4604 - val_loss: 1.0565 - val_accuracy: 0.5324 - lr: 3.7500e-06\n",
            "Epoch 28/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0103 - accuracy: 0.4626\n",
            "Epoch 00028: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 660ms/step - loss: 1.0103 - accuracy: 0.4626 - val_loss: 1.0537 - val_accuracy: 0.5305 - lr: 3.7500e-06\n",
            "Epoch 29/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0025 - accuracy: 0.4580\n",
            "Epoch 00029: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.874999952633516e-06.\n",
            "197/197 [==============================] - 130s 659ms/step - loss: 1.0025 - accuracy: 0.4580 - val_loss: 1.0555 - val_accuracy: 0.5324 - lr: 3.7500e-06\n",
            "Epoch 30/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0020 - accuracy: 0.4689\n",
            "Epoch 00030: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 658ms/step - loss: 1.0020 - accuracy: 0.4689 - val_loss: 1.0506 - val_accuracy: 0.5346 - lr: 1.8750e-06\n",
            "Epoch 31/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0022 - accuracy: 0.4666\n",
            "Epoch 00031: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 655ms/step - loss: 1.0022 - accuracy: 0.4666 - val_loss: 1.0497 - val_accuracy: 0.5309 - lr: 1.8750e-06\n",
            "Epoch 32/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0018 - accuracy: 0.4669\n",
            "Epoch 00032: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.37499976316758e-07.\n",
            "197/197 [==============================] - 129s 655ms/step - loss: 1.0018 - accuracy: 0.4669 - val_loss: 1.0517 - val_accuracy: 0.5324 - lr: 1.8750e-06\n",
            "Epoch 33/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0017 - accuracy: 0.4697\n",
            "Epoch 00033: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 658ms/step - loss: 1.0017 - accuracy: 0.4697 - val_loss: 1.0491 - val_accuracy: 0.5320 - lr: 9.3750e-07\n",
            "Epoch 34/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0005 - accuracy: 0.4687\n",
            "Epoch 00034: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 659ms/step - loss: 1.0005 - accuracy: 0.4687 - val_loss: 1.0486 - val_accuracy: 0.5357 - lr: 9.3750e-07\n",
            "Epoch 35/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0004 - accuracy: 0.4628\n",
            "Epoch 00035: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.68749988158379e-07.\n",
            "197/197 [==============================] - 130s 660ms/step - loss: 1.0004 - accuracy: 0.4628 - val_loss: 1.0483 - val_accuracy: 0.5335 - lr: 9.3750e-07\n",
            "Epoch 36/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9957 - accuracy: 0.4695\n",
            "Epoch 00036: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 660ms/step - loss: 0.9957 - accuracy: 0.4695 - val_loss: 1.0479 - val_accuracy: 0.5361 - lr: 4.6875e-07\n",
            "Epoch 37/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9963 - accuracy: 0.4722\n",
            "Epoch 00037: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 660ms/step - loss: 0.9963 - accuracy: 0.4722 - val_loss: 1.0470 - val_accuracy: 0.5368 - lr: 4.6875e-07\n",
            "Epoch 38/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9986 - accuracy: 0.4610\n",
            "Epoch 00038: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 131s 663ms/step - loss: 0.9986 - accuracy: 0.4610 - val_loss: 1.0472 - val_accuracy: 0.5365 - lr: 4.6875e-07\n",
            "Epoch 39/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9979 - accuracy: 0.4703\n",
            "Epoch 00039: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 131s 663ms/step - loss: 0.9979 - accuracy: 0.4703 - val_loss: 1.0459 - val_accuracy: 0.5365 - lr: 4.6875e-07\n",
            "Epoch 40/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9938 - accuracy: 0.4783\n",
            "Epoch 00040: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 659ms/step - loss: 0.9938 - accuracy: 0.4783 - val_loss: 1.0452 - val_accuracy: 0.5372 - lr: 4.6875e-07\n",
            "Epoch 41/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9956 - accuracy: 0.4730\n",
            "Epoch 00041: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 661ms/step - loss: 0.9956 - accuracy: 0.4730 - val_loss: 1.0475 - val_accuracy: 0.5312 - lr: 4.6875e-07\n",
            "Epoch 42/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9951 - accuracy: 0.4717\n",
            "Epoch 00042: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 658ms/step - loss: 0.9951 - accuracy: 0.4717 - val_loss: 1.0453 - val_accuracy: 0.5372 - lr: 4.6875e-07\n",
            "Epoch 43/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9952 - accuracy: 0.4789\n",
            "Epoch 00043: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 2.343749940791895e-07.\n",
            "197/197 [==============================] - 129s 657ms/step - loss: 0.9952 - accuracy: 0.4789 - val_loss: 1.0457 - val_accuracy: 0.5320 - lr: 4.6875e-07\n",
            "Epoch 44/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9992 - accuracy: 0.4792\n",
            "Epoch 00044: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 657ms/step - loss: 0.9992 - accuracy: 0.4792 - val_loss: 1.0450 - val_accuracy: 0.5335 - lr: 2.3437e-07\n",
            "Epoch 45/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9969 - accuracy: 0.4631\n",
            "Epoch 00045: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 657ms/step - loss: 0.9969 - accuracy: 0.4631 - val_loss: 1.0449 - val_accuracy: 0.5353 - lr: 2.3437e-07\n",
            "Epoch 46/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9967 - accuracy: 0.4757\n",
            "Epoch 00046: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 656ms/step - loss: 0.9967 - accuracy: 0.4757 - val_loss: 1.0437 - val_accuracy: 0.5391 - lr: 2.3437e-07\n",
            "Epoch 47/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9898 - accuracy: 0.4727\n",
            "Epoch 00047: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 657ms/step - loss: 0.9898 - accuracy: 0.4727 - val_loss: 1.0451 - val_accuracy: 0.5350 - lr: 2.3437e-07\n",
            "Epoch 48/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9919 - accuracy: 0.4685\n",
            "Epoch 00048: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 656ms/step - loss: 0.9919 - accuracy: 0.4685 - val_loss: 1.0438 - val_accuracy: 0.5365 - lr: 2.3437e-07\n",
            "Epoch 49/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0003 - accuracy: 0.4754\n",
            "Epoch 00049: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.1718749703959475e-07.\n",
            "197/197 [==============================] - 129s 656ms/step - loss: 1.0003 - accuracy: 0.4754 - val_loss: 1.0434 - val_accuracy: 0.5387 - lr: 2.3437e-07\n",
            "Epoch 50/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9933 - accuracy: 0.4752\n",
            "Epoch 00050: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 655ms/step - loss: 0.9933 - accuracy: 0.4752 - val_loss: 1.0473 - val_accuracy: 0.5294 - lr: 1.1719e-07\n",
            "Epoch 51/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9961 - accuracy: 0.4816\n",
            "Epoch 00051: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 659ms/step - loss: 0.9961 - accuracy: 0.4816 - val_loss: 1.0446 - val_accuracy: 0.5339 - lr: 1.1719e-07\n",
            "Epoch 52/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9953 - accuracy: 0.4697\n",
            "Epoch 00052: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 5.859374851979737e-08.\n",
            "197/197 [==============================] - 129s 657ms/step - loss: 0.9953 - accuracy: 0.4697 - val_loss: 1.0444 - val_accuracy: 0.5324 - lr: 1.1719e-07\n",
            "Epoch 53/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9961 - accuracy: 0.4719\n",
            "Epoch 00053: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 657ms/step - loss: 0.9961 - accuracy: 0.4719 - val_loss: 1.0444 - val_accuracy: 0.5368 - lr: 5.8594e-08\n",
            "Epoch 54/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9961 - accuracy: 0.4735\n",
            "Epoch 00054: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 658ms/step - loss: 0.9961 - accuracy: 0.4735 - val_loss: 1.0429 - val_accuracy: 0.5365 - lr: 5.8594e-08\n",
            "Epoch 55/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9924 - accuracy: 0.4752\n",
            "Epoch 00055: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00055: ReduceLROnPlateau reducing learning rate to 2.9296874259898686e-08.\n",
            "197/197 [==============================] - 129s 656ms/step - loss: 0.9924 - accuracy: 0.4752 - val_loss: 1.0437 - val_accuracy: 0.5365 - lr: 5.8594e-08\n",
            "Epoch 56/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9948 - accuracy: 0.4794\n",
            "Epoch 00056: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 134s 680ms/step - loss: 0.9948 - accuracy: 0.4794 - val_loss: 1.0441 - val_accuracy: 0.5372 - lr: 2.9297e-08\n",
            "Epoch 57/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9922 - accuracy: 0.4697\n",
            "Epoch 00057: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 131s 666ms/step - loss: 0.9922 - accuracy: 0.4697 - val_loss: 1.0448 - val_accuracy: 0.5353 - lr: 2.9297e-08\n",
            "Epoch 58/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9970 - accuracy: 0.4649\n",
            "Epoch 00058: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.4648437129949343e-08.\n",
            "197/197 [==============================] - 130s 662ms/step - loss: 0.9970 - accuracy: 0.4649 - val_loss: 1.0453 - val_accuracy: 0.5327 - lr: 2.9297e-08\n",
            "Epoch 59/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.4668\n",
            "Epoch 00059: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 131s 663ms/step - loss: 0.9983 - accuracy: 0.4668 - val_loss: 1.0443 - val_accuracy: 0.5365 - lr: 1.4648e-08\n",
            "Epoch 60/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9962 - accuracy: 0.4693\n",
            "Epoch 00060: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 131s 664ms/step - loss: 0.9962 - accuracy: 0.4693 - val_loss: 1.0450 - val_accuracy: 0.5331 - lr: 1.4648e-08\n",
            "Epoch 61/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9909 - accuracy: 0.4701\n",
            "Epoch 00061: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00061: ReduceLROnPlateau reducing learning rate to 7.324218564974672e-09.\n",
            "197/197 [==============================] - 131s 663ms/step - loss: 0.9909 - accuracy: 0.4701 - val_loss: 1.0435 - val_accuracy: 0.5357 - lr: 1.4648e-08\n",
            "Epoch 62/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9877 - accuracy: 0.4755\n",
            "Epoch 00062: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 132s 672ms/step - loss: 0.9877 - accuracy: 0.4755 - val_loss: 1.0454 - val_accuracy: 0.5324 - lr: 7.3242e-09\n",
            "Epoch 63/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9955 - accuracy: 0.4818\n",
            "Epoch 00063: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 131s 664ms/step - loss: 0.9955 - accuracy: 0.4818 - val_loss: 1.0427 - val_accuracy: 0.5368 - lr: 7.3242e-09\n",
            "Epoch 64/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0020 - accuracy: 0.4676\n",
            "Epoch 00064: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00064: ReduceLROnPlateau reducing learning rate to 3.662109282487336e-09.\n",
            "197/197 [==============================] - 129s 657ms/step - loss: 1.0020 - accuracy: 0.4676 - val_loss: 1.0442 - val_accuracy: 0.5346 - lr: 7.3242e-09\n",
            "Epoch 65/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9957 - accuracy: 0.4697\n",
            "Epoch 00065: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 130s 661ms/step - loss: 0.9957 - accuracy: 0.4697 - val_loss: 1.0437 - val_accuracy: 0.5361 - lr: 3.6621e-09\n",
            "Epoch 66/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9933 - accuracy: 0.4775\n",
            "Epoch 00066: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 131s 664ms/step - loss: 0.9933 - accuracy: 0.4775 - val_loss: 1.0439 - val_accuracy: 0.5342 - lr: 3.6621e-09\n",
            "Epoch 67/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9889 - accuracy: 0.4661\n",
            "Epoch 00067: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.831054641243668e-09.\n",
            "197/197 [==============================] - 129s 655ms/step - loss: 0.9889 - accuracy: 0.4661 - val_loss: 1.0429 - val_accuracy: 0.5327 - lr: 3.6621e-09\n",
            "Epoch 68/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9885 - accuracy: 0.4708\n",
            "Epoch 00068: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 655ms/step - loss: 0.9885 - accuracy: 0.4708 - val_loss: 1.0447 - val_accuracy: 0.5339 - lr: 1.8311e-09\n",
            "Epoch 69/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9876 - accuracy: 0.4709\n",
            "Epoch 00069: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 653ms/step - loss: 0.9876 - accuracy: 0.4709 - val_loss: 1.0445 - val_accuracy: 0.5327 - lr: 1.8311e-09\n",
            "Epoch 70/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9955 - accuracy: 0.4701\n",
            "Epoch 00070: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00070: ReduceLROnPlateau reducing learning rate to 9.15527320621834e-10.\n",
            "197/197 [==============================] - 129s 654ms/step - loss: 0.9955 - accuracy: 0.4701 - val_loss: 1.0448 - val_accuracy: 0.5331 - lr: 1.8311e-09\n",
            "Epoch 71/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9965 - accuracy: 0.4757\n",
            "Epoch 00071: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 129s 654ms/step - loss: 0.9965 - accuracy: 0.4757 - val_loss: 1.0447 - val_accuracy: 0.5327 - lr: 9.1553e-10\n",
            "Epoch 72/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9885 - accuracy: 0.4768\n",
            "Epoch 00072: val_loss did not improve from 1.66363\n",
            "197/197 [==============================] - 128s 652ms/step - loss: 0.9885 - accuracy: 0.4768 - val_loss: 1.0459 - val_accuracy: 0.5324 - lr: 9.1553e-10\n",
            "Epoch 73/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9961 - accuracy: 0.4652\n",
            "Epoch 00073: val_loss did not improve from 1.66363\n",
            "\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 4.57763660310917e-10.\n",
            "197/197 [==============================] - 129s 654ms/step - loss: 0.9961 - accuracy: 0.4652 - val_loss: 1.0447 - val_accuracy: 0.5331 - lr: 9.1553e-10\n",
            "Epoch 00073: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "383eb86x9FvQ",
        "colab_type": "text"
      },
      "source": [
        "# **Accuracy and Loss Graph**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKv_2jc7O4Se",
        "colab_type": "text"
      },
      "source": [
        "### **Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtDoga8c10Ly",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "79b7ad71-5c52-48d3-b4b0-eada27a35926"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.title('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6pg2k6xO5p8",
        "colab_type": "text"
      },
      "source": [
        "### **Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT1Pr5RmWJkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f6b8c902-171a-4347-c459-5a61bfc60ed3"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.title('loss')\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1cWi7orKdUr",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ea-ST316j3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0d302290-79f1-474e-8d0d-7cd3f5209336"
      },
      "source": [
        "test_data.reset()\n",
        "predictions = model.predict_generator(test_data, steps=test_data.samples/test_data.batch_size,verbose=1)\n",
        "y_pred= np.argmax(predictions, axis=1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-99bdc2a40673>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n",
            "1002/1002 [==============================] - 13s 13ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJfzBH2gcQ5M",
        "colab_type": "text"
      },
      "source": [
        "### **Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDJVF1dbWQlu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "8973f05c-9c7a-451d-ed9d-20103d0d58fe"
      },
      "source": [
        "Y_pred = predictions\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(name_as_indexes_test, y_pred))\n",
        "print('Classification Report')\n",
        "classes_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "print(classification_report(name_as_indexes_test, y_pred, target_names=classes_names))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[ 17   5   8   8   3   0   0]\n",
            " [  2  32   4   1   5   0   3]\n",
            " [  2  13  78   9  15   0   8]\n",
            " [  0   4   4   7   0   0   0]\n",
            " [  6   8  16  15  56   5   4]\n",
            " [  5  41  73  46 121 308  55]\n",
            " [  0   0   0   0   0   0  15]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.53      0.41      0.47        41\n",
            "         bcc       0.31      0.68      0.43        47\n",
            "         bkl       0.43      0.62      0.51       125\n",
            "          df       0.08      0.47      0.14        15\n",
            "         mel       0.28      0.51      0.36       110\n",
            "          nv       0.98      0.47      0.64       649\n",
            "        vasc       0.18      1.00      0.30        15\n",
            "\n",
            "    accuracy                           0.51      1002\n",
            "   macro avg       0.40      0.60      0.41      1002\n",
            "weighted avg       0.76      0.51      0.56      1002\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMxOe1qPcUSr",
        "colab_type": "text"
      },
      "source": [
        "### **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWSBDzE5WXgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "0a5a67f3-27c0-4978-f4be-575fa4da67cf"
      },
      "source": [
        "cm = (confusion_matrix(name_as_indexes_test, y_pred))\n",
        "\n",
        "plot_confusion_matrix(cm, classes_names)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[ 17   5   8   8   3   0   0]\n",
            " [  2  32   4   1   5   0   3]\n",
            " [  2  13  78   9  15   0   8]\n",
            " [  0   4   4   7   0   0   0]\n",
            " [  6   8  16  15  56   5   4]\n",
            " [  5  41  73  46 121 308  55]\n",
            " [  0   0   0   0   0   0  15]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbXcAwdJ-1tX",
        "colab_type": "text"
      },
      "source": [
        "### **Sensitivity & Specificity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH-wStPm6T7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = sum(sum(cm))\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc7FeOe56a9-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8c081d8a-61fb-4e7b-cc83-fbd9e529bb6c"
      },
      "source": [
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sensitivity: 0.7727\n",
            "specificity: 0.9412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkrPLbkZdva9",
        "colab_type": "text"
      },
      "source": [
        "# **Grad-CAM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_OVC2F8xfR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_conv2d = 'conv5_block16_2_conv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyWQAabav_ST",
        "colab_type": "text"
      },
      "source": [
        "### **AKIEC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5JjxhIrqN5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "akiec_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0026492.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGMmNOxxiHxq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "5fabbfcc-ada9-45e1-dc21-425b7c22fc30"
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, akiec_img, layer_name=last_conv2d)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model prediction:\n",
            "\tmel            \t(4)\twith probability 0.366\n",
            "\tbkl            \t(2)\twith probability 0.176\n",
            "\takiec          \t(0)\twith probability 0.164\n",
            "\tdf             \t(3)\twith probability 0.092\n",
            "\tbcc            \t(1)\twith probability 0.084\n",
            "Explanation for 'mel'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c01fefc2e1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradcam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguided_gradcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_saliency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0makiec_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_conv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/ham10000_utils_functions.py\u001b[0m in \u001b[0;36mcompute_saliency\u001b[0;34m(model, guided_model, img_path, layer_name, cls, visualize, save)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_decode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Explanation for '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mgradcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguided_backprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguided_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mguided_gradcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradcam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ham10000_utils_functions.py\u001b[0m in \u001b[0;36mgrad_cam\u001b[0;34m(input_model, image, cls, layer_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0my_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mconv_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Normalize if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# grads = normalize(grads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients_v2\u001b[0;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    303\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    489\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    492\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    493\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D53Hg3-mwNj-",
        "colab_type": "text"
      },
      "source": [
        "### **BCC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-APRYghPa4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bcc_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0024332.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IavEoR0qwWO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, bcc_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnzfOod3xC7p",
        "colab_type": "text"
      },
      "source": [
        "### **BKL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Za1Ztu0kxVpc",
        "colab": {}
      },
      "source": [
        "bkl_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0025548.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xc_tDIcsxVpg",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, bkl_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2qr1BF9xEnD",
        "colab_type": "text"
      },
      "source": [
        "### **DF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w3400LGvxWEF",
        "colab": {}
      },
      "source": [
        "df_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0033626.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S92MquPFxWEI",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, df_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y6JOyRWxJy7",
        "colab_type": "text"
      },
      "source": [
        "### **MEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9mRW-epcxWdq",
        "colab": {}
      },
      "source": [
        "mel_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0024516.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g4j2KO_pxWdv",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, mel_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKEm-_WKxHRq",
        "colab_type": "text"
      },
      "source": [
        "### **NV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "opRTYW5SxXgR",
        "colab": {}
      },
      "source": [
        "nv_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0024349.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iVbqIHvGxXgV",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, nv_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVFPRGL0xHtK",
        "colab_type": "text"
      },
      "source": [
        "### **VASC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YuzSPvQ9xXJg",
        "colab": {}
      },
      "source": [
        "vasc_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0025452.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ol1Ik8qDxXJj",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, vasc_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYJYt3yOB47l",
        "colab_type": "text"
      },
      "source": [
        "# **Download Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFv5jXItB-fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuVkAwOn3A9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('/content/Focal-Loss_ResNet50_model.h5')\n",
        "files.download('/content/Focal-Loss_ResNet50_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}