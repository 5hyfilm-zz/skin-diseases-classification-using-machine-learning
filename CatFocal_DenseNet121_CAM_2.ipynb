{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CatFocal_DenseNet121_CAM_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPm9tj6Dn9ZrbbL0amSfiTZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filmerxyz/JSTP-22_SkinDiseaseClassificationUsingMachineLearning/blob/master/CatFocal_DenseNet121_CAM_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGAbDjt3rz_5",
        "colab_type": "text"
      },
      "source": [
        "# **Check GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KeAnM3PXlUe",
        "colab_type": "code",
        "outputId": "b402d198-35f2-4801-f2a1-68e06fe1bdea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun  1 02:38:17 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbD3Qq816yZZ",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tch5If72HQeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from os.path import join\n",
        "\n",
        "from ham10000_utils_functions import plot_confusion_matrix, normalize, deprocess_image, my_decode_predictions, guided_backprop, grad_cam, compute_saliency"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPwDTos761Oq",
        "colab_type": "text"
      },
      "source": [
        "# **Clone Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHjfNRvqza-U",
        "colab_type": "code",
        "outputId": "230c5323-c5a1-4d39-bad1-be8e937ea1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/EvilPickle-PCSHSPT/ham10000-with-one-image-folder"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ham10000-with-one-image-folder'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 10045 (delta 4), reused 7 (delta 2), pack-reused 10036\n",
            "Receiving objects: 100% (10045/10045), 2.57 GiB | 51.33 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "Checking out files: 100% (10022/10022), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__IXKxBZVymL",
        "colab_type": "text"
      },
      "source": [
        "# **Constant Variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ2LKSeHQRnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 7\n",
        "STEPS = 16\n",
        "\n",
        "LR = 3e-5 # Learning rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrpBmL7mVlJC",
        "colab_type": "text"
      },
      "source": [
        "# **Prepare Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnsBJBcPL3SG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('/content/ham10000-with-one-image-folder/HAM10000_metadata.csv')\n",
        "data['image_full_name']=data['image_id']+'.jpg'\n",
        "X=data[['image_full_name','dx','lesion_id']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rt4v6YTM0Fr",
        "colab_type": "code",
        "outputId": "7656bb19-a353-4d34-84fb-544bd764f233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>image_full_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0027419.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0025030.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0026769.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>ISIC_0025661.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>ISIC_0031633.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx  ...   sex  localization   image_full_name\n",
              "0  HAM_0000118  ISIC_0027419  bkl  ...  male         scalp  ISIC_0027419.jpg\n",
              "1  HAM_0000118  ISIC_0025030  bkl  ...  male         scalp  ISIC_0025030.jpg\n",
              "2  HAM_0002730  ISIC_0026769  bkl  ...  male         scalp  ISIC_0026769.jpg\n",
              "3  HAM_0002730  ISIC_0025661  bkl  ...  male         scalp  ISIC_0025661.jpg\n",
              "4  HAM_0001466  ISIC_0031633  bkl  ...  male           ear  ISIC_0031633.jpg\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_1JsUvHGMGi",
        "colab_type": "text"
      },
      "source": [
        "### **Split Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1q1WsAhM-HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Y=X.pop('dx').to_frame()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ghodz0zOJ0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.concat([X_train,y_train],axis=1)\n",
        "val = pd.concat([X_val,y_val],axis=1)\n",
        "test = pd.concat([X_test,y_test],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG6iaiiyMHmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train['dx'])\n",
        "name_as_indexes_train = encoder.transform(train['dx']) \n",
        "train['label'] = name_as_indexes_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLryd9huOStO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(val['dx'])\n",
        "name_as_indexes_val = encoder.transform(val['dx']) \n",
        "val['label'] = name_as_indexes_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VYdnvBOOUek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder=LabelEncoder()\n",
        "encoder.fit(test['dx'])\n",
        "name_as_indexes_test = encoder.transform(test['dx']) \n",
        "test['label'] = name_as_indexes_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDOtGZx7YiJa",
        "colab_type": "text"
      },
      "source": [
        "### **Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6snNZRZOWaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = ImageDataGenerator(rescale = 1./255,\n",
        "                                     rotation_range=360,  \n",
        "                                     zoom_range = 0.3,\n",
        "                                     horizontal_flip=True,\n",
        "                                     vertical_flip=True,\n",
        "                                     fill_mode='reflect')\n",
        "                                    \n",
        "val_generator=ImageDataGenerator(rescale = 1./255)\n",
        "test_generator=ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdF3KvYwOfC5",
        "colab_type": "code",
        "outputId": "d3a96ec2-4736-491f-ec7b-d3ea31443a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_data= train_generator.flow_from_dataframe(dataframe=train, x_col=\"image_full_name\", y_col=\"dx\",\n",
        "                                                directory='/content/ham10000-with-one-image-folder/HAM1000_images',\n",
        "                                                shuffle=True,batch_size=32,class_mode=\"categorical\",target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
        "\n",
        "val_data= val_generator.flow_from_dataframe(dataframe=val, x_col=\"image_full_name\", y_col=\"dx\",\n",
        "                                              directory='/content/ham10000-with-one-image-folder/HAM1000_images',\n",
        "                                              shuffle=True,batch_size=32,class_mode='categorical',target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
        "\n",
        "test_data= test_generator.flow_from_dataframe(dataframe=test, x_col=\"image_full_name\", y_col=\"dx\",\n",
        "                                              directory='/content/ham10000-with-one-image-folder/HAM1000_images',\n",
        "                                              shuffle=False,batch_size=1,class_mode=None,target_size=(IMG_WIDTH,IMG_HEIGHT))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6309 validated image filenames belonging to 7 classes.\n",
            "Found 2704 validated image filenames belonging to 7 classes.\n",
            "Found 1002 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WOs0EjX8Ot2",
        "colab_type": "text"
      },
      "source": [
        "# **Focal Loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9H8QLiwJ_rc",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/umbertogriffo/focal-loss-keras\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he4CnLjdH8c5",
        "colab_type": "text"
      },
      "source": [
        "$$\\text{FL}(p_t) = -\\alpha_t (1 - p_t)^{\\gamma} \\, \\text{log}(p_t)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvORsbwy69hO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_focal_loss(gamma=2., alpha=.25):\n",
        "    \"\"\"\n",
        "    Softmax version of focal loss.\n",
        "           m\n",
        "      FL = ∑  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n",
        "          c=1\n",
        "      where m = number of classes, c = class and o = observation\n",
        "    Parameters:\n",
        "      alpha -- the same as weighing factor in balanced cross entropy\n",
        "      gamma -- focusing parameter for modulating factor (1-p)\n",
        "    Default value:\n",
        "      gamma -- 2.0 as mentioned in the paper\n",
        "      alpha -- 0.25 as mentioned in the paper\n",
        "    References:\n",
        "        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n",
        "        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
        "    Usage:\n",
        "     model.compile(loss=[categorical_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
        "    \"\"\"\n",
        "    def categorical_focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        :param y_true: A tensor of the same shape as `y_pred`\n",
        "        :param y_pred: A tensor resulting from a softmax\n",
        "        :return: Output tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        # Scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "\n",
        "        # Clip the prediction value to prevent NaN's and Inf's\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        # Calculate Cross Entropy\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "\n",
        "        # Calculate Focal Loss\n",
        "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
        "\n",
        "        # Compute mean loss in mini_batch\n",
        "        return K.mean(loss, axis=1)\n",
        "\n",
        "    return categorical_focal_loss_fixed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM_7koKYSwRX",
        "colab_type": "text"
      },
      "source": [
        "# Class Weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqppou6MSvrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(name_as_indexes_train), name_as_indexes_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhjJOtHPTOqN",
        "colab_type": "code",
        "outputId": "aa2fb2d4-fdf3-4532-91f3-387da886d0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "class_weights"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.76870748,  2.82534707,  1.32542017, 11.40867993,  1.28939301,\n",
              "        0.21181803, 10.24188312])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoJAN5opTvV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_class_weight_dict = { i : class_weights[i] for i in range(0, len(class_weights) ) }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nM6ctD3Ty8H",
        "colab_type": "code",
        "outputId": "fbb4c346-29ce-4772-d930-87929d3b199a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_class_weight_dict"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 4.7687074829931975,\n",
              " 1: 2.825347066726377,\n",
              " 2: 1.3254201680672268,\n",
              " 3: 11.408679927667269,\n",
              " 4: 1.2893930104230533,\n",
              " 5: 0.21181802920933357,\n",
              " 6: 10.241883116883116}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivQqzr9X8T8Z",
        "colab_type": "text"
      },
      "source": [
        "# **Build Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6NKOM5-VHcm",
        "colab_type": "text"
      },
      "source": [
        "### **Use DenseNet121 + fine tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "982Ib3LtLZ19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  base_model = tf.keras.applications.DenseNet121(include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3), weights='imagenet')\n",
        "  \n",
        "  for layer in base_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "  average_pooling_layer = GlobalAveragePooling2D()(base_model.output)\n",
        "  \n",
        "  fc_layer = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(average_pooling_layer)\n",
        "  fc_layer = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  fc_layer = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  fc_layer = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  fc_layer = Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(fc_layer)\n",
        "  bn_layer = BatchNormalization()(fc_layer)\n",
        "  dropout_layer = Dropout(0.25)(bn_layer)\n",
        "  prediction_layer = Dense(units=7, activation='softmax', name='prediction')(dropout_layer)\n",
        "  model = Model(inputs=base_model.input, outputs=prediction_layer)\n",
        "  \n",
        "  model.compile(optimizer=Adam(LR), loss=[categorical_focal_loss(alpha=.75, gamma=2)], metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quSBa9F3Qdqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "64a29596-f3d0-429f-cc79-a2911c66f4ac"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TFNv-FGLdgd",
        "colab_type": "text"
      },
      "source": [
        "### **Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1bAKncT_-0g",
        "colab_type": "code",
        "outputId": "ac7cef84-57f0-4fa3-e86d-5db54b02c228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
            "                                                                 conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
            "                                                                 conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
            "                                                                 conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
            "                                                                 conv2_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
            "                                                                 conv2_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
            "                                                                 conv2_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
            "                                                                 conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
            "                                                                 conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
            "                                                                 conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
            "                                                                 conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
            "                                                                 conv3_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
            "                                                                 conv3_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
            "                                                                 conv3_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
            "                                                                 conv3_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
            "                                                                 conv3_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
            "                                                                 conv3_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
            "                                                                 conv3_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
            "                                                                 conv3_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
            "                                                                 conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
            "                                                                 conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
            "                                                                 conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
            "                                                                 conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
            "                                                                 conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
            "                                                                 conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
            "                                                                 conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
            "                                                                 conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
            "                                                                 conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
            "                                                                 conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
            "                                                                 conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
            "                                                                 conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
            "                                                                 conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
            "                                                                 conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
            "                                                                 conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
            "                                                                 conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
            "                                                                 conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
            "                                                                 conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
            "                                                                 conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
            "                                                                 conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
            "                                                                 conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
            "                                                                 conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
            "                                                                 conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
            "                                                                 conv4_block24_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
            "                                                                 conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
            "                                                                 conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
            "                                                                 conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
            "                                                                 conv5_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
            "                                                                 conv5_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
            "                                                                 conv5_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
            "                                                                 conv5_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
            "                                                                 conv5_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
            "                                                                 conv5_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
            "                                                                 conv5_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
            "                                                                 conv5_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
            "                                                                 conv5_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
            "                                                                 conv5_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
            "                                                                 conv5_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
            "                                                                 conv5_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
            "                                                                 conv5_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1024)         0           relu[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          524800      global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          131328      dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 32)           2080        dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32)           128         dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32)           0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 7)            231         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,737,223\n",
            "Trainable params: 783,303\n",
            "Non-trainable params: 6,953,920\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUkpZH2iO2HT",
        "colab_type": "text"
      },
      "source": [
        "### **Callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W01_QL-DQujb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = '/content/CatFL_DenseNet121_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-TRuxDhSBVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPtUnf9tSCYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnTxHeV9ym7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_plateau = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=.5, min_lr=1-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGLVL4QTSDOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_list = [checkpoint, early_stop, reduce_plateau]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tWxLCM5VFYz",
        "colab_type": "text"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-tzC-r3SEBp",
        "colab_type": "code",
        "outputId": "3f8ad0b3-eead-473f-f8b1-6ec0da66fea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_data,\n",
        "                    steps_per_epoch=train_data.samples//train_data.batch_size,\n",
        "                    validation_data=val_data,\n",
        "                    validation_steps=val_data.samples//val_data.batch_size,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=cb_list,\n",
        "                    verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.4466 - accuracy: 0.2735\n",
            "Epoch 00001: val_loss improved from -inf to 1.33033, saving model to /content/CatFL_DenseNet121_model.h5\n",
            "197/197 [==============================] - 154s 781ms/step - loss: 1.4466 - accuracy: 0.2735 - val_loss: 1.3303 - val_accuracy: 0.5603 - lr: 3.0000e-05\n",
            "Epoch 2/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.3088 - accuracy: 0.4384\n",
            "Epoch 00002: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 151s 766ms/step - loss: 1.3088 - accuracy: 0.4384 - val_loss: 1.2275 - val_accuracy: 0.5934 - lr: 3.0000e-05\n",
            "Epoch 3/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.2103 - accuracy: 0.5165\n",
            "Epoch 00003: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 151s 768ms/step - loss: 1.2103 - accuracy: 0.5165 - val_loss: 1.1419 - val_accuracy: 0.6551 - lr: 3.0000e-05\n",
            "Epoch 4/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.1271 - accuracy: 0.5702\n",
            "Epoch 00004: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 763ms/step - loss: 1.1271 - accuracy: 0.5702 - val_loss: 1.0638 - val_accuracy: 0.6868 - lr: 3.0000e-05\n",
            "Epoch 5/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 1.0578 - accuracy: 0.6098\n",
            "Epoch 00005: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 761ms/step - loss: 1.0578 - accuracy: 0.6098 - val_loss: 1.0001 - val_accuracy: 0.6975 - lr: 3.0000e-05\n",
            "Epoch 6/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9987 - accuracy: 0.6304\n",
            "Epoch 00006: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 151s 768ms/step - loss: 0.9987 - accuracy: 0.6304 - val_loss: 0.9411 - val_accuracy: 0.7254 - lr: 3.0000e-05\n",
            "Epoch 7/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.9455 - accuracy: 0.6505\n",
            "Epoch 00007: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 763ms/step - loss: 0.9455 - accuracy: 0.6505 - val_loss: 0.9022 - val_accuracy: 0.7210 - lr: 3.0000e-05\n",
            "Epoch 8/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.8983 - accuracy: 0.6729\n",
            "Epoch 00008: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 760ms/step - loss: 0.8983 - accuracy: 0.6729 - val_loss: 0.8550 - val_accuracy: 0.7392 - lr: 3.0000e-05\n",
            "Epoch 9/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.8575 - accuracy: 0.6814\n",
            "Epoch 00009: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 758ms/step - loss: 0.8575 - accuracy: 0.6814 - val_loss: 0.8190 - val_accuracy: 0.7478 - lr: 3.0000e-05\n",
            "Epoch 10/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.8185 - accuracy: 0.6970\n",
            "Epoch 00010: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 153s 775ms/step - loss: 0.8185 - accuracy: 0.6970 - val_loss: 0.7942 - val_accuracy: 0.7295 - lr: 3.0000e-05\n",
            "Epoch 11/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.7836 - accuracy: 0.7073\n",
            "Epoch 00011: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 152s 772ms/step - loss: 0.7836 - accuracy: 0.7073 - val_loss: 0.7514 - val_accuracy: 0.7481 - lr: 3.0000e-05\n",
            "Epoch 12/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.7498 - accuracy: 0.7195\n",
            "Epoch 00012: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 151s 767ms/step - loss: 0.7498 - accuracy: 0.7195 - val_loss: 0.7223 - val_accuracy: 0.7493 - lr: 3.0000e-05\n",
            "Epoch 13/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.7188\n",
            "Epoch 00013: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 152s 770ms/step - loss: 0.7221 - accuracy: 0.7188 - val_loss: 0.6962 - val_accuracy: 0.7526 - lr: 3.0000e-05\n",
            "Epoch 14/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.7261\n",
            "Epoch 00014: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 153s 774ms/step - loss: 0.6931 - accuracy: 0.7261 - val_loss: 0.6700 - val_accuracy: 0.7593 - lr: 3.0000e-05\n",
            "Epoch 15/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.6660 - accuracy: 0.7357\n",
            "Epoch 00015: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 152s 772ms/step - loss: 0.6660 - accuracy: 0.7357 - val_loss: 0.6440 - val_accuracy: 0.7641 - lr: 3.0000e-05\n",
            "Epoch 16/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.7387\n",
            "Epoch 00016: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 152s 773ms/step - loss: 0.6414 - accuracy: 0.7387 - val_loss: 0.6200 - val_accuracy: 0.7671 - lr: 3.0000e-05\n",
            "Epoch 17/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.6189 - accuracy: 0.7367\n",
            "Epoch 00017: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 152s 772ms/step - loss: 0.6189 - accuracy: 0.7367 - val_loss: 0.6014 - val_accuracy: 0.7582 - lr: 3.0000e-05\n",
            "Epoch 18/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.5936 - accuracy: 0.7497\n",
            "Epoch 00018: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 152s 772ms/step - loss: 0.5936 - accuracy: 0.7497 - val_loss: 0.5727 - val_accuracy: 0.7764 - lr: 3.0000e-05\n",
            "Epoch 19/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.7516\n",
            "Epoch 00019: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 153s 774ms/step - loss: 0.5731 - accuracy: 0.7516 - val_loss: 0.5556 - val_accuracy: 0.7746 - lr: 3.0000e-05\n",
            "Epoch 20/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.7532\n",
            "Epoch 00020: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 152s 771ms/step - loss: 0.5500 - accuracy: 0.7532 - val_loss: 0.5403 - val_accuracy: 0.7671 - lr: 3.0000e-05\n",
            "Epoch 21/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.7585\n",
            "Epoch 00021: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 764ms/step - loss: 0.5328 - accuracy: 0.7585 - val_loss: 0.5158 - val_accuracy: 0.7798 - lr: 3.0000e-05\n",
            "Epoch 22/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.7604\n",
            "Epoch 00022: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 756ms/step - loss: 0.5123 - accuracy: 0.7604 - val_loss: 0.4977 - val_accuracy: 0.7883 - lr: 3.0000e-05\n",
            "Epoch 23/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.7591\n",
            "Epoch 00023: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 757ms/step - loss: 0.4950 - accuracy: 0.7591 - val_loss: 0.4853 - val_accuracy: 0.7746 - lr: 3.0000e-05\n",
            "Epoch 24/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.7631\n",
            "Epoch 00024: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 757ms/step - loss: 0.4791 - accuracy: 0.7631 - val_loss: 0.4637 - val_accuracy: 0.7909 - lr: 3.0000e-05\n",
            "Epoch 25/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.7749\n",
            "Epoch 00025: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 754ms/step - loss: 0.4600 - accuracy: 0.7749 - val_loss: 0.4486 - val_accuracy: 0.7939 - lr: 3.0000e-05\n",
            "Epoch 26/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.7771\n",
            "Epoch 00026: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 761ms/step - loss: 0.4456 - accuracy: 0.7771 - val_loss: 0.4355 - val_accuracy: 0.7876 - lr: 3.0000e-05\n",
            "Epoch 27/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.4313 - accuracy: 0.7774\n",
            "Epoch 00027: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 151s 764ms/step - loss: 0.4313 - accuracy: 0.7774 - val_loss: 0.4194 - val_accuracy: 0.7894 - lr: 3.0000e-05\n",
            "Epoch 28/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.7795\n",
            "Epoch 00028: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 762ms/step - loss: 0.4179 - accuracy: 0.7795 - val_loss: 0.4077 - val_accuracy: 0.7894 - lr: 3.0000e-05\n",
            "Epoch 29/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.7837\n",
            "Epoch 00029: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 764ms/step - loss: 0.4044 - accuracy: 0.7837 - val_loss: 0.3959 - val_accuracy: 0.8017 - lr: 3.0000e-05\n",
            "Epoch 30/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.7837\n",
            "Epoch 00030: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 759ms/step - loss: 0.3920 - accuracy: 0.7837 - val_loss: 0.3814 - val_accuracy: 0.7995 - lr: 3.0000e-05\n",
            "Epoch 31/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.7875\n",
            "Epoch 00031: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 760ms/step - loss: 0.3790 - accuracy: 0.7875 - val_loss: 0.3743 - val_accuracy: 0.7902 - lr: 3.0000e-05\n",
            "Epoch 32/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.7923\n",
            "Epoch 00032: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 151s 764ms/step - loss: 0.3675 - accuracy: 0.7923 - val_loss: 0.3627 - val_accuracy: 0.8028 - lr: 3.0000e-05\n",
            "Epoch 33/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.7900\n",
            "Epoch 00033: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 151s 768ms/step - loss: 0.3575 - accuracy: 0.7900 - val_loss: 0.3529 - val_accuracy: 0.7946 - lr: 3.0000e-05\n",
            "Epoch 34/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.7953\n",
            "Epoch 00034: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 762ms/step - loss: 0.3464 - accuracy: 0.7953 - val_loss: 0.3439 - val_accuracy: 0.7999 - lr: 3.0000e-05\n",
            "Epoch 35/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.7974\n",
            "Epoch 00035: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 762ms/step - loss: 0.3369 - accuracy: 0.7974 - val_loss: 0.3365 - val_accuracy: 0.7917 - lr: 3.0000e-05\n",
            "Epoch 36/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.7969\n",
            "Epoch 00036: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 759ms/step - loss: 0.3279 - accuracy: 0.7969 - val_loss: 0.3250 - val_accuracy: 0.8051 - lr: 3.0000e-05\n",
            "Epoch 37/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.7940\n",
            "Epoch 00037: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 751ms/step - loss: 0.3198 - accuracy: 0.7940 - val_loss: 0.3148 - val_accuracy: 0.8099 - lr: 3.0000e-05\n",
            "Epoch 38/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.7993\n",
            "Epoch 00038: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 748ms/step - loss: 0.3112 - accuracy: 0.7993 - val_loss: 0.3074 - val_accuracy: 0.8047 - lr: 3.0000e-05\n",
            "Epoch 39/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.3037 - accuracy: 0.8040\n",
            "Epoch 00039: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 758ms/step - loss: 0.3037 - accuracy: 0.8040 - val_loss: 0.3079 - val_accuracy: 0.7731 - lr: 3.0000e-05\n",
            "Epoch 40/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.8112\n",
            "Epoch 00040: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 760ms/step - loss: 0.2946 - accuracy: 0.8112 - val_loss: 0.2989 - val_accuracy: 0.7790 - lr: 3.0000e-05\n",
            "Epoch 41/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.8056\n",
            "Epoch 00041: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 761ms/step - loss: 0.2873 - accuracy: 0.8056 - val_loss: 0.2871 - val_accuracy: 0.7995 - lr: 3.0000e-05\n",
            "Epoch 42/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.8052\n",
            "Epoch 00042: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 749ms/step - loss: 0.2816 - accuracy: 0.8052 - val_loss: 0.2806 - val_accuracy: 0.7972 - lr: 3.0000e-05\n",
            "Epoch 43/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.8074\n",
            "Epoch 00043: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 748ms/step - loss: 0.2752 - accuracy: 0.8074 - val_loss: 0.2758 - val_accuracy: 0.8013 - lr: 3.0000e-05\n",
            "Epoch 44/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.8219\n",
            "Epoch 00044: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 746ms/step - loss: 0.2671 - accuracy: 0.8219 - val_loss: 0.2658 - val_accuracy: 0.8188 - lr: 3.0000e-05\n",
            "Epoch 45/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.8160\n",
            "Epoch 00045: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 747ms/step - loss: 0.2610 - accuracy: 0.8160 - val_loss: 0.2656 - val_accuracy: 0.7954 - lr: 3.0000e-05\n",
            "Epoch 46/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.8150\n",
            "Epoch 00046: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 746ms/step - loss: 0.2552 - accuracy: 0.8150 - val_loss: 0.2548 - val_accuracy: 0.8166 - lr: 3.0000e-05\n",
            "Epoch 47/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2494 - accuracy: 0.8273\n",
            "Epoch 00047: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 746ms/step - loss: 0.2494 - accuracy: 0.8273 - val_loss: 0.2523 - val_accuracy: 0.8099 - lr: 3.0000e-05\n",
            "Epoch 48/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.8185\n",
            "Epoch 00048: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 146s 742ms/step - loss: 0.2438 - accuracy: 0.8185 - val_loss: 0.2484 - val_accuracy: 0.8010 - lr: 3.0000e-05\n",
            "Epoch 49/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.8252\n",
            "Epoch 00049: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 746ms/step - loss: 0.2386 - accuracy: 0.8252 - val_loss: 0.2410 - val_accuracy: 0.8062 - lr: 3.0000e-05\n",
            "Epoch 50/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.8279\n",
            "Epoch 00050: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 760ms/step - loss: 0.2335 - accuracy: 0.8279 - val_loss: 0.2373 - val_accuracy: 0.7984 - lr: 3.0000e-05\n",
            "Epoch 51/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.8251\n",
            "Epoch 00051: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 756ms/step - loss: 0.2284 - accuracy: 0.8251 - val_loss: 0.2315 - val_accuracy: 0.8092 - lr: 3.0000e-05\n",
            "Epoch 52/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.8273\n",
            "Epoch 00052: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 752ms/step - loss: 0.2239 - accuracy: 0.8273 - val_loss: 0.2287 - val_accuracy: 0.8095 - lr: 3.0000e-05\n",
            "Epoch 53/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.8342\n",
            "Epoch 00053: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 754ms/step - loss: 0.2184 - accuracy: 0.8342 - val_loss: 0.2257 - val_accuracy: 0.7984 - lr: 3.0000e-05\n",
            "Epoch 54/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.8356\n",
            "Epoch 00054: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 758ms/step - loss: 0.2145 - accuracy: 0.8356 - val_loss: 0.2181 - val_accuracy: 0.8114 - lr: 3.0000e-05\n",
            "Epoch 55/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.8316\n",
            "Epoch 00055: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 754ms/step - loss: 0.2106 - accuracy: 0.8316 - val_loss: 0.2172 - val_accuracy: 0.7987 - lr: 3.0000e-05\n",
            "Epoch 56/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2058 - accuracy: 0.8337\n",
            "Epoch 00056: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 757ms/step - loss: 0.2058 - accuracy: 0.8337 - val_loss: 0.2155 - val_accuracy: 0.7920 - lr: 3.0000e-05\n",
            "Epoch 57/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.8318\n",
            "Epoch 00057: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 754ms/step - loss: 0.2027 - accuracy: 0.8318 - val_loss: 0.2089 - val_accuracy: 0.8092 - lr: 3.0000e-05\n",
            "Epoch 58/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1973 - accuracy: 0.8389\n",
            "Epoch 00058: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 753ms/step - loss: 0.1973 - accuracy: 0.8389 - val_loss: 0.2025 - val_accuracy: 0.8170 - lr: 3.0000e-05\n",
            "Epoch 59/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.8393\n",
            "Epoch 00059: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 749ms/step - loss: 0.1935 - accuracy: 0.8393 - val_loss: 0.1991 - val_accuracy: 0.8132 - lr: 3.0000e-05\n",
            "Epoch 60/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.8418\n",
            "Epoch 00060: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 749ms/step - loss: 0.1896 - accuracy: 0.8418 - val_loss: 0.1957 - val_accuracy: 0.8069 - lr: 3.0000e-05\n",
            "Epoch 61/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.8444\n",
            "Epoch 00061: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 750ms/step - loss: 0.1862 - accuracy: 0.8444 - val_loss: 0.1936 - val_accuracy: 0.8114 - lr: 3.0000e-05\n",
            "Epoch 62/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.8428\n",
            "Epoch 00062: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 753ms/step - loss: 0.1827 - accuracy: 0.8428 - val_loss: 0.1878 - val_accuracy: 0.8080 - lr: 3.0000e-05\n",
            "Epoch 63/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.8483\n",
            "Epoch 00063: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 746ms/step - loss: 0.1786 - accuracy: 0.8483 - val_loss: 0.1845 - val_accuracy: 0.8144 - lr: 3.0000e-05\n",
            "Epoch 64/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1746 - accuracy: 0.8542\n",
            "Epoch 00064: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 756ms/step - loss: 0.1746 - accuracy: 0.8542 - val_loss: 0.1843 - val_accuracy: 0.8006 - lr: 3.0000e-05\n",
            "Epoch 65/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.8514\n",
            "Epoch 00065: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 749ms/step - loss: 0.1724 - accuracy: 0.8514 - val_loss: 0.1803 - val_accuracy: 0.8088 - lr: 3.0000e-05\n",
            "Epoch 66/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.8506\n",
            "Epoch 00066: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 746ms/step - loss: 0.1693 - accuracy: 0.8506 - val_loss: 0.1779 - val_accuracy: 0.8114 - lr: 3.0000e-05\n",
            "Epoch 67/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1665 - accuracy: 0.8456\n",
            "Epoch 00067: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 745ms/step - loss: 0.1665 - accuracy: 0.8456 - val_loss: 0.1752 - val_accuracy: 0.8088 - lr: 3.0000e-05\n",
            "Epoch 68/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1636 - accuracy: 0.8480\n",
            "Epoch 00068: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 146s 741ms/step - loss: 0.1636 - accuracy: 0.8480 - val_loss: 0.1766 - val_accuracy: 0.7999 - lr: 3.0000e-05\n",
            "Epoch 69/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1600 - accuracy: 0.8528\n",
            "Epoch 00069: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 744ms/step - loss: 0.1600 - accuracy: 0.8528 - val_loss: 0.1665 - val_accuracy: 0.8278 - lr: 3.0000e-05\n",
            "Epoch 70/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.8561\n",
            "Epoch 00070: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 146s 741ms/step - loss: 0.1564 - accuracy: 0.8561 - val_loss: 0.1668 - val_accuracy: 0.8065 - lr: 3.0000e-05\n",
            "Epoch 71/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.8627\n",
            "Epoch 00071: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 745ms/step - loss: 0.1538 - accuracy: 0.8627 - val_loss: 0.1629 - val_accuracy: 0.8147 - lr: 3.0000e-05\n",
            "Epoch 72/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1514 - accuracy: 0.8536\n",
            "Epoch 00072: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 146s 742ms/step - loss: 0.1514 - accuracy: 0.8536 - val_loss: 0.1627 - val_accuracy: 0.7920 - lr: 3.0000e-05\n",
            "Epoch 73/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.8604\n",
            "Epoch 00073: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 146s 742ms/step - loss: 0.1484 - accuracy: 0.8604 - val_loss: 0.1575 - val_accuracy: 0.8136 - lr: 3.0000e-05\n",
            "Epoch 74/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.8587\n",
            "Epoch 00074: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 746ms/step - loss: 0.1467 - accuracy: 0.8587 - val_loss: 0.1541 - val_accuracy: 0.8199 - lr: 3.0000e-05\n",
            "Epoch 75/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.8622\n",
            "Epoch 00075: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 146s 741ms/step - loss: 0.1433 - accuracy: 0.8622 - val_loss: 0.1509 - val_accuracy: 0.8237 - lr: 3.0000e-05\n",
            "Epoch 76/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.8679\n",
            "Epoch 00076: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 146s 742ms/step - loss: 0.1399 - accuracy: 0.8679 - val_loss: 0.1532 - val_accuracy: 0.8043 - lr: 3.0000e-05\n",
            "Epoch 77/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.8579\n",
            "Epoch 00077: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 146s 741ms/step - loss: 0.1390 - accuracy: 0.8579 - val_loss: 0.1452 - val_accuracy: 0.8259 - lr: 3.0000e-05\n",
            "Epoch 78/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.8667\n",
            "Epoch 00078: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 146s 742ms/step - loss: 0.1355 - accuracy: 0.8667 - val_loss: 0.1461 - val_accuracy: 0.8132 - lr: 3.0000e-05\n",
            "Epoch 79/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.8713\n",
            "Epoch 00079: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 746ms/step - loss: 0.1333 - accuracy: 0.8713 - val_loss: 0.1419 - val_accuracy: 0.8196 - lr: 3.0000e-05\n",
            "Epoch 80/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.8753\n",
            "Epoch 00080: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 748ms/step - loss: 0.1302 - accuracy: 0.8753 - val_loss: 0.1400 - val_accuracy: 0.8203 - lr: 3.0000e-05\n",
            "Epoch 81/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.8670\n",
            "Epoch 00081: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 745ms/step - loss: 0.1293 - accuracy: 0.8670 - val_loss: 0.1377 - val_accuracy: 0.8203 - lr: 3.0000e-05\n",
            "Epoch 82/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.8706\n",
            "Epoch 00082: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 748ms/step - loss: 0.1265 - accuracy: 0.8706 - val_loss: 0.1372 - val_accuracy: 0.8237 - lr: 3.0000e-05\n",
            "Epoch 83/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.8695\n",
            "Epoch 00083: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 747ms/step - loss: 0.1250 - accuracy: 0.8695 - val_loss: 0.1343 - val_accuracy: 0.8222 - lr: 3.0000e-05\n",
            "Epoch 84/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.8770\n",
            "Epoch 00084: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 753ms/step - loss: 0.1216 - accuracy: 0.8770 - val_loss: 0.1314 - val_accuracy: 0.8263 - lr: 3.0000e-05\n",
            "Epoch 85/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.8804\n",
            "Epoch 00085: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 751ms/step - loss: 0.1194 - accuracy: 0.8804 - val_loss: 0.1315 - val_accuracy: 0.8181 - lr: 3.0000e-05\n",
            "Epoch 86/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.8746\n",
            "Epoch 00086: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 752ms/step - loss: 0.1181 - accuracy: 0.8746 - val_loss: 0.1276 - val_accuracy: 0.8229 - lr: 3.0000e-05\n",
            "Epoch 87/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.8797\n",
            "Epoch 00087: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 758ms/step - loss: 0.1154 - accuracy: 0.8797 - val_loss: 0.1273 - val_accuracy: 0.8144 - lr: 3.0000e-05\n",
            "Epoch 88/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.8775\n",
            "Epoch 00088: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 763ms/step - loss: 0.1139 - accuracy: 0.8775 - val_loss: 0.1241 - val_accuracy: 0.8315 - lr: 3.0000e-05\n",
            "Epoch 89/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.8781\n",
            "Epoch 00089: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 762ms/step - loss: 0.1121 - accuracy: 0.8781 - val_loss: 0.1275 - val_accuracy: 0.8158 - lr: 3.0000e-05\n",
            "Epoch 90/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.8753\n",
            "Epoch 00090: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 151s 764ms/step - loss: 0.1098 - accuracy: 0.8753 - val_loss: 0.1192 - val_accuracy: 0.8330 - lr: 3.0000e-05\n",
            "Epoch 91/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.8837\n",
            "Epoch 00091: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 151s 764ms/step - loss: 0.1078 - accuracy: 0.8837 - val_loss: 0.1194 - val_accuracy: 0.8251 - lr: 3.0000e-05\n",
            "Epoch 92/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.8837\n",
            "Epoch 00092: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 763ms/step - loss: 0.1069 - accuracy: 0.8837 - val_loss: 0.1212 - val_accuracy: 0.8121 - lr: 3.0000e-05\n",
            "Epoch 93/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.8845\n",
            "Epoch 00093: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 756ms/step - loss: 0.1051 - accuracy: 0.8845 - val_loss: 0.1159 - val_accuracy: 0.8289 - lr: 3.0000e-05\n",
            "Epoch 94/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.8840\n",
            "Epoch 00094: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 150s 762ms/step - loss: 0.1029 - accuracy: 0.8840 - val_loss: 0.1143 - val_accuracy: 0.8333 - lr: 3.0000e-05\n",
            "Epoch 95/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.8815\n",
            "Epoch 00095: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 759ms/step - loss: 0.1016 - accuracy: 0.8815 - val_loss: 0.1122 - val_accuracy: 0.8292 - lr: 3.0000e-05\n",
            "Epoch 96/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.8859\n",
            "Epoch 00096: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 149s 756ms/step - loss: 0.0999 - accuracy: 0.8859 - val_loss: 0.1131 - val_accuracy: 0.8199 - lr: 3.0000e-05\n",
            "Epoch 97/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.8866\n",
            "Epoch 00097: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 753ms/step - loss: 0.0986 - accuracy: 0.8866 - val_loss: 0.1090 - val_accuracy: 0.8333 - lr: 3.0000e-05\n",
            "Epoch 98/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.8861\n",
            "Epoch 00098: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 751ms/step - loss: 0.0967 - accuracy: 0.8861 - val_loss: 0.1091 - val_accuracy: 0.8278 - lr: 3.0000e-05\n",
            "Epoch 99/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.8926\n",
            "Epoch 00099: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 148s 749ms/step - loss: 0.0952 - accuracy: 0.8926 - val_loss: 0.1062 - val_accuracy: 0.8352 - lr: 3.0000e-05\n",
            "Epoch 100/100\n",
            "197/197 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.8913\n",
            "Epoch 00100: val_loss did not improve from 1.33033\n",
            "197/197 [==============================] - 147s 748ms/step - loss: 0.0938 - accuracy: 0.8913 - val_loss: 0.1053 - val_accuracy: 0.8162 - lr: 3.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "383eb86x9FvQ",
        "colab_type": "text"
      },
      "source": [
        "# **Accuracy and Loss Graph**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKv_2jc7O4Se",
        "colab_type": "text"
      },
      "source": [
        "### **Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtDoga8c10Ly",
        "colab_type": "code",
        "outputId": "f8eaf4a8-f61f-4659-bdd7-99b5310d1d67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.title('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6pg2k6xO5p8",
        "colab_type": "text"
      },
      "source": [
        "### **Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT1Pr5RmWJkU",
        "colab_type": "code",
        "outputId": "1d059c02-445e-4b24-f808-97a34d21299d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.title('loss')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1cWi7orKdUr",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ea-ST316j3r",
        "colab_type": "code",
        "outputId": "3d3e5af8-f760-4d6f-831a-992573b0e1cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "test_data.reset()\n",
        "predictions = model.predict_generator(test_data, steps=test_data.samples/test_data.batch_size,verbose=1)\n",
        "y_pred= np.argmax(predictions, axis=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-30-99bdc2a40673>:2: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n",
            "1002/1002 [==============================] - 14s 14ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJfzBH2gcQ5M",
        "colab_type": "text"
      },
      "source": [
        "### **Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDJVF1dbWQlu",
        "colab_type": "code",
        "outputId": "9bdc686b-ed19-4d31-ee49-851d3bbedb73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "Y_pred = predictions\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(name_as_indexes_test, y_pred))\n",
        "print('Classification Report')\n",
        "classes_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "print(classification_report(name_as_indexes_test, y_pred, target_names=classes_names))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[ 12   5  12   0  11   1   0]\n",
            " [  1  30   4   0   7   5   0]\n",
            " [  0   2  80   1  20  22   0]\n",
            " [  0   2   3   6   0   4   0]\n",
            " [  0   1   4   0  89  16   0]\n",
            " [  0   1  10   0  48 589   1]\n",
            " [  0   0   0   0   0   1  14]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec       0.92      0.29      0.44        41\n",
            "         bcc       0.73      0.64      0.68        47\n",
            "         bkl       0.71      0.64      0.67       125\n",
            "          df       0.86      0.40      0.55        15\n",
            "         mel       0.51      0.81      0.62       110\n",
            "          nv       0.92      0.91      0.92       649\n",
            "        vasc       0.93      0.93      0.93        15\n",
            "\n",
            "    accuracy                           0.82      1002\n",
            "   macro avg       0.80      0.66      0.69      1002\n",
            "weighted avg       0.84      0.82      0.82      1002\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMxOe1qPcUSr",
        "colab_type": "text"
      },
      "source": [
        "### **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWSBDzE5WXgr",
        "colab_type": "code",
        "outputId": "98096498-f270-4f1a-f1f7-0a060a7557ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "cm = (confusion_matrix(name_as_indexes_test, y_pred))\n",
        "\n",
        "plot_confusion_matrix(cm, classes_names)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[ 12   5  12   0  11   1   0]\n",
            " [  1  30   4   0   7   5   0]\n",
            " [  0   2  80   1  20  22   0]\n",
            " [  0   2   3   6   0   4   0]\n",
            " [  0   1   4   0  89  16   0]\n",
            " [  0   1  10   0  48 589   1]\n",
            " [  0   0   0   0   0   1  14]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbXcAwdJ-1tX",
        "colab_type": "text"
      },
      "source": [
        "### **Sensitivity & Specificity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH-wStPm6T7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = sum(sum(cm))\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc7FeOe56a9-",
        "colab_type": "code",
        "outputId": "3dc52af1-501a-4b6f-a473-399288da0079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
        "print(\"specificity: {:.4f}\".format(specificity))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sensitivity: 0.7059\n",
            "specificity: 0.9677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkrPLbkZdva9",
        "colab_type": "text"
      },
      "source": [
        "# **Grad-CAM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_OVC2F8xfR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_conv2d = 'conv5_block16_2_conv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyWQAabav_ST",
        "colab_type": "text"
      },
      "source": [
        "### **AKIEC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5JjxhIrqN5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "akiec_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0026492.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGMmNOxxiHxq",
        "colab_type": "code",
        "outputId": "18a0a617-5821-4615-b001-7a32a0de8f11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, akiec_img, layer_name=last_conv2d)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model prediction:\n",
            "\tmel            \t(4)\twith probability 0.939\n",
            "\tnv             \t(5)\twith probability 0.032\n",
            "\tbkl            \t(2)\twith probability 0.013\n",
            "\takiec          \t(0)\twith probability 0.009\n",
            "\tbcc            \t(1)\twith probability 0.003\n",
            "Explanation for 'mel'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c01fefc2e1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradcam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguided_gradcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_saliency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0makiec_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_conv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/ham10000_utils_functions.py\u001b[0m in \u001b[0;36mcompute_saliency\u001b[0;34m(model, guided_model, img_path, layer_name, cls, visualize, save)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_decode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Explanation for '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mgradcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguided_backprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguided_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessed_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mguided_gradcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradcam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ham10000_utils_functions.py\u001b[0m in \u001b[0;36mgrad_cam\u001b[0;34m(input_model, image, cls, layer_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0my_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mconv_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Normalize if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# grads = normalize(grads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients_v2\u001b[0;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    303\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    489\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    492\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    493\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D53Hg3-mwNj-",
        "colab_type": "text"
      },
      "source": [
        "### **BCC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-APRYghPa4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bcc_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0024332.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IavEoR0qwWO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, bcc_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnzfOod3xC7p",
        "colab_type": "text"
      },
      "source": [
        "### **BKL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Za1Ztu0kxVpc",
        "colab": {}
      },
      "source": [
        "bkl_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0025548.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xc_tDIcsxVpg",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, bkl_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2qr1BF9xEnD",
        "colab_type": "text"
      },
      "source": [
        "### **DF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w3400LGvxWEF",
        "colab": {}
      },
      "source": [
        "df_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0033626.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S92MquPFxWEI",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, df_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y6JOyRWxJy7",
        "colab_type": "text"
      },
      "source": [
        "### **MEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9mRW-epcxWdq",
        "colab": {}
      },
      "source": [
        "mel_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0024516.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g4j2KO_pxWdv",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, mel_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKEm-_WKxHRq",
        "colab_type": "text"
      },
      "source": [
        "### **NV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "opRTYW5SxXgR",
        "colab": {}
      },
      "source": [
        "nv_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0024349.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iVbqIHvGxXgV",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, nv_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVFPRGL0xHtK",
        "colab_type": "text"
      },
      "source": [
        "### **VASC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YuzSPvQ9xXJg",
        "colab": {}
      },
      "source": [
        "vasc_img = '/content/ham10000-with-one-image-folder/HAM1000_images/ISIC_0025452.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ol1Ik8qDxXJj",
        "colab": {}
      },
      "source": [
        "gradcam, gb, guided_gradcam = compute_saliency(model, model, vasc_img, layer_name=last_conv2d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYJYt3yOB47l",
        "colab_type": "text"
      },
      "source": [
        "# **Download Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFv5jXItB-fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuVkAwOn3A9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('/content/Focal-Loss_ResNet50_model.h5')\n",
        "files.download('/content/Focal-Loss_ResNet50_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}